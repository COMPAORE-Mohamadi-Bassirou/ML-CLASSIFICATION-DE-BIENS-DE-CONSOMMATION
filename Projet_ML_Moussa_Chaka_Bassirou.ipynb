{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bafc361-dbec-42c8-8abf-5769e54f69fe",
   "metadata": {},
   "source": [
    "<h1 style = \"text-align:center;color:blue;font-family:algerian;font-size:35px;\">Classifiez des biens de consommation</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9ce9f2-6d23-42c4-bbf2-645c7b58b775",
   "metadata": {},
   "source": [
    "<h1 style = \"text-align:center;color:blue;font-size:25px;\">Bassirou_Chaka_Moussa</h1>\n",
    "<h1 style = \"text-align:center;color:red;font-size:25px;\">élèves ingénieurs statisticiens économistes</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb8540e-d008-4e1d-8c11-17e0fb3843a1",
   "metadata": {},
   "source": [
    "## **Summary**\n",
    "\n",
    "Cette étude examine la **faisabilité** de concevoir un système automatisé de classification d’articles en différentes catégories, en se basant notamment sur des **images illustratives** ou du **texte en anglais**. L’objectif est d’atteindre une précision suffisante pour garantir une attribution des catégories à la fois fiable et autonome. L’analyse repose sur un jeu de données comprenant **15 variables** et **1 050 observations**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ea735c-5a14-41fc-813e-5090c26dd44c",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#d4f0ff; font-size:20px;padding:20px; border-left:25px solid #1c8adb;\">\n",
    "    <strong>Packages </strong> \n",
    "</div>Dans cette section, nous importons les bibliothèques nécessaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cb764b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6acd4a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.image import imread\n",
    "import time\n",
    "import random\n",
    "import operator\n",
    "import scipy.cluster.hierarchy as shc\n",
    "import multiprocessing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize, FreqDist\n",
    "from sklearn import (preprocessing,\n",
    "                     manifold,\n",
    "                     decomposition)\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans, DBSCAN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.decomposition import NMF\n",
    "from PIL import Image, ImageOps, ImageFilter\n",
    "#import tensorflow as tf\n",
    "#import keras\n",
    "#from keras.preprocessing import image\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3d9e20-0583-48eb-95bb-391677229ace",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#d4f0ff; font-size:20px;padding:20px; border-left:25px solid #1c8adb;\">\n",
    "    <strong> Importation des fonctions utiles </strong> \n",
    "</div>Afin d'améliorer la lisibilité et d'assurer un meilleur confort de lecture de ce notebook, les fonctions dédiées à la manipulation des données et à la création des graphiques ont été centralisées dans le fichier project_functions.py.\n",
    "\n",
    "\n",
    "Ces fonctions sont ensuite importées grâce à la ligne de code suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0800449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import project_functions as pf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be4ffaf-359d-4994-8b16-93027c9f176c",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#d4f0ff; font-size:20px;padding:20px; border-left:25px solid #1c8adb;\">\n",
    "    <strong> Data collection </strong> \n",
    "</div> Dans cette partie nous allons importer le jeu des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b96fcfcd-1a85-4214-8264-ac8461d57f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/hp/Desktop/Projet_ML/Base/flipkart_com-ecommerce_sample_1050(2).csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1440d95-377b-4db4-a8d4-8623806ae656",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#d4f0ff; font-size:20px;padding:20px; border-left:25px solid #1c8adb;\">\n",
    "    <strong> 1. DESCRIPTION DU JEU DE DONNEES </strong> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1282cf",
   "metadata": {},
   "source": [
    "___\n",
    "### **1.1 Apperçu des données**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e9a0002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniq_id</th>\n",
       "      <th>crawl_timestamp</th>\n",
       "      <th>product_url</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_category_tree</th>\n",
       "      <th>pid</th>\n",
       "      <th>retail_price</th>\n",
       "      <th>discounted_price</th>\n",
       "      <th>image</th>\n",
       "      <th>is_FK_Advantage_product</th>\n",
       "      <th>description</th>\n",
       "      <th>product_rating</th>\n",
       "      <th>overall_rating</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_specifications</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55b85ea15a1536d46b7190ad6fff8ce7</td>\n",
       "      <td>2016-04-30 03:22:56 +0000</td>\n",
       "      <td>http://www.flipkart.com/elegance-polyester-mul...</td>\n",
       "      <td>Elegance Polyester Multicolor Abstract Eyelet ...</td>\n",
       "      <td>[\"Home Furnishing &gt;&gt; Curtains &amp; Accessories &gt;&gt;...</td>\n",
       "      <td>CRNEG7BKMFFYHQ8Z</td>\n",
       "      <td>1899.0</td>\n",
       "      <td>899.0</td>\n",
       "      <td>55b85ea15a1536d46b7190ad6fff8ce7.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>Key Features of Elegance Polyester Multicolor ...</td>\n",
       "      <td>No rating available</td>\n",
       "      <td>No rating available</td>\n",
       "      <td>Elegance</td>\n",
       "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Brand\", \"v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7b72c92c2f6c40268628ec5f14c6d590</td>\n",
       "      <td>2016-04-30 03:22:56 +0000</td>\n",
       "      <td>http://www.flipkart.com/sathiyas-cotton-bath-t...</td>\n",
       "      <td>Sathiyas Cotton Bath Towel</td>\n",
       "      <td>[\"Baby Care &gt;&gt; Baby Bath &amp; Skin &gt;&gt; Baby Bath T...</td>\n",
       "      <td>BTWEGFZHGBXPHZUH</td>\n",
       "      <td>600.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>7b72c92c2f6c40268628ec5f14c6d590.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>Specifications of Sathiyas Cotton Bath Towel (...</td>\n",
       "      <td>No rating available</td>\n",
       "      <td>No rating available</td>\n",
       "      <td>Sathiyas</td>\n",
       "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Machine Wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64d5d4a258243731dc7bbb1eef49ad74</td>\n",
       "      <td>2016-04-30 03:22:56 +0000</td>\n",
       "      <td>http://www.flipkart.com/eurospa-cotton-terry-f...</td>\n",
       "      <td>Eurospa Cotton Terry Face Towel Set</td>\n",
       "      <td>[\"Baby Care &gt;&gt; Baby Bath &amp; Skin &gt;&gt; Baby Bath T...</td>\n",
       "      <td>BTWEG6SHXTDB2A2Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64d5d4a258243731dc7bbb1eef49ad74.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>Key Features of Eurospa Cotton Terry Face Towe...</td>\n",
       "      <td>No rating available</td>\n",
       "      <td>No rating available</td>\n",
       "      <td>Eurospa</td>\n",
       "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Material\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d4684dcdc759dd9cdf41504698d737d8</td>\n",
       "      <td>2016-06-20 08:49:52 +0000</td>\n",
       "      <td>http://www.flipkart.com/santosh-royal-fashion-...</td>\n",
       "      <td>SANTOSH ROYAL FASHION Cotton Printed King size...</td>\n",
       "      <td>[\"Home Furnishing &gt;&gt; Bed Linen &gt;&gt; Bedsheets &gt;&gt;...</td>\n",
       "      <td>BDSEJT9UQWHDUBH4</td>\n",
       "      <td>2699.0</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>d4684dcdc759dd9cdf41504698d737d8.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>Key Features of SANTOSH ROYAL FASHION Cotton P...</td>\n",
       "      <td>No rating available</td>\n",
       "      <td>No rating available</td>\n",
       "      <td>SANTOSH ROYAL FASHION</td>\n",
       "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Brand\", \"v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6325b6870c54cd47be6ebfbffa620ec7</td>\n",
       "      <td>2016-06-20 08:49:52 +0000</td>\n",
       "      <td>http://www.flipkart.com/jaipur-print-cotton-fl...</td>\n",
       "      <td>Jaipur Print Cotton Floral King sized Double B...</td>\n",
       "      <td>[\"Home Furnishing &gt;&gt; Bed Linen &gt;&gt; Bedsheets &gt;&gt;...</td>\n",
       "      <td>BDSEJTHNGWVGWWQU</td>\n",
       "      <td>2599.0</td>\n",
       "      <td>698.0</td>\n",
       "      <td>6325b6870c54cd47be6ebfbffa620ec7.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>Key Features of Jaipur Print Cotton Floral Kin...</td>\n",
       "      <td>No rating available</td>\n",
       "      <td>No rating available</td>\n",
       "      <td>Jaipur Print</td>\n",
       "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Machine Wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            uniq_id            crawl_timestamp  \\\n",
       "0  55b85ea15a1536d46b7190ad6fff8ce7  2016-04-30 03:22:56 +0000   \n",
       "1  7b72c92c2f6c40268628ec5f14c6d590  2016-04-30 03:22:56 +0000   \n",
       "2  64d5d4a258243731dc7bbb1eef49ad74  2016-04-30 03:22:56 +0000   \n",
       "3  d4684dcdc759dd9cdf41504698d737d8  2016-06-20 08:49:52 +0000   \n",
       "4  6325b6870c54cd47be6ebfbffa620ec7  2016-06-20 08:49:52 +0000   \n",
       "\n",
       "                                         product_url  \\\n",
       "0  http://www.flipkart.com/elegance-polyester-mul...   \n",
       "1  http://www.flipkart.com/sathiyas-cotton-bath-t...   \n",
       "2  http://www.flipkart.com/eurospa-cotton-terry-f...   \n",
       "3  http://www.flipkart.com/santosh-royal-fashion-...   \n",
       "4  http://www.flipkart.com/jaipur-print-cotton-fl...   \n",
       "\n",
       "                                        product_name  \\\n",
       "0  Elegance Polyester Multicolor Abstract Eyelet ...   \n",
       "1                         Sathiyas Cotton Bath Towel   \n",
       "2                Eurospa Cotton Terry Face Towel Set   \n",
       "3  SANTOSH ROYAL FASHION Cotton Printed King size...   \n",
       "4  Jaipur Print Cotton Floral King sized Double B...   \n",
       "\n",
       "                               product_category_tree               pid  \\\n",
       "0  [\"Home Furnishing >> Curtains & Accessories >>...  CRNEG7BKMFFYHQ8Z   \n",
       "1  [\"Baby Care >> Baby Bath & Skin >> Baby Bath T...  BTWEGFZHGBXPHZUH   \n",
       "2  [\"Baby Care >> Baby Bath & Skin >> Baby Bath T...  BTWEG6SHXTDB2A2Y   \n",
       "3  [\"Home Furnishing >> Bed Linen >> Bedsheets >>...  BDSEJT9UQWHDUBH4   \n",
       "4  [\"Home Furnishing >> Bed Linen >> Bedsheets >>...  BDSEJTHNGWVGWWQU   \n",
       "\n",
       "   retail_price  discounted_price                                 image  \\\n",
       "0        1899.0             899.0  55b85ea15a1536d46b7190ad6fff8ce7.jpg   \n",
       "1         600.0             449.0  7b72c92c2f6c40268628ec5f14c6d590.jpg   \n",
       "2           NaN               NaN  64d5d4a258243731dc7bbb1eef49ad74.jpg   \n",
       "3        2699.0            1299.0  d4684dcdc759dd9cdf41504698d737d8.jpg   \n",
       "4        2599.0             698.0  6325b6870c54cd47be6ebfbffa620ec7.jpg   \n",
       "\n",
       "   is_FK_Advantage_product                                        description  \\\n",
       "0                    False  Key Features of Elegance Polyester Multicolor ...   \n",
       "1                    False  Specifications of Sathiyas Cotton Bath Towel (...   \n",
       "2                    False  Key Features of Eurospa Cotton Terry Face Towe...   \n",
       "3                    False  Key Features of SANTOSH ROYAL FASHION Cotton P...   \n",
       "4                    False  Key Features of Jaipur Print Cotton Floral Kin...   \n",
       "\n",
       "        product_rating       overall_rating                  brand  \\\n",
       "0  No rating available  No rating available               Elegance   \n",
       "1  No rating available  No rating available               Sathiyas   \n",
       "2  No rating available  No rating available                Eurospa   \n",
       "3  No rating available  No rating available  SANTOSH ROYAL FASHION   \n",
       "4  No rating available  No rating available           Jaipur Print   \n",
       "\n",
       "                              product_specifications  \n",
       "0  {\"product_specification\"=>[{\"key\"=>\"Brand\", \"v...  \n",
       "1  {\"product_specification\"=>[{\"key\"=>\"Machine Wa...  \n",
       "2  {\"product_specification\"=>[{\"key\"=>\"Material\",...  \n",
       "3  {\"product_specification\"=>[{\"key\"=>\"Brand\", \"v...  \n",
       "4  {\"product_specification\"=>[{\"key\"=>\"Machine Wa...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68923668",
   "metadata": {},
   "source": [
    "Chaque ligne représente un produit, incluant son nom ainsi que ses caractéristiques associées telles que la description, la catégorie, la marque, une image, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fced2132",
   "metadata": {},
   "source": [
    "___\n",
    "### **1.2 Structure des données**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8c41ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d167533",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.describe_dataset({'sample e-commerce':[df, \"Produits\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7180e8a5",
   "metadata": {},
   "source": [
    "Le jeu de données contient 1050 lignes et 15 colonnes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10b6ebe",
   "metadata": {},
   "source": [
    "___\n",
    "### **1.3 Données manquantes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702d417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.plot_percentage_missing_values_for(df, 20, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a35452d",
   "metadata": {},
   "source": [
    "De manière générale, les colonnes sont très bien renseignées (avec un taux de remplissage supérieur à 90 %), à l’exception de la colonne \"brand\", qui présente plus de 30 % de valeurs manquantes.Alors nous allons remplacer les valeurs manquantes de brand par \" \"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fbe14e-003f-44d9-9203-efa9e94f71f6",
   "metadata": {},
   "source": [
    "Pour un projet de classification, remplacer les valeurs manquantes de brand par une chaîne vide (\" \") conserve la nature textuelle de la variable et facilite son encodage sans introduire de biais. Cette méthode est bien tolérée par les algorithmes comme les arbres ou forêts aléatoires, qui gèrent efficacement les modalités neutres, assurant ainsi un prétraitement simple et adapté au pipeline de classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "874278c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les valeurs manquantes pour la variable \"brand\" sont remplacés par \"\".\n",
    "df[\"brand\"].fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922fdcb3",
   "metadata": {},
   "source": [
    "___\n",
    "### **1.4 Les catégories produits**\n",
    "\n",
    "Chaque produit est classé selon une hiérarchie à plusieurs niveaux, représentée sous forme d’arborescence. Les informations relatives à cette classification sont contenues dans la colonne **product_category_tree.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855a273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple de la catégorie d'un produit\n",
    "print(df[\"product_category_tree\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d55acee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère la colomne \"product_category_tree\"\n",
    "list_categories_0, list_categories_1 = [], []\n",
    "for txt in df[\"product_category_tree\"] :\n",
    "    \n",
    "    list_categories_0.append(txt.split(\">>\")[0].split(\"\\\"\")[1].strip()) # split du nom par >> et on récupère la première partie\n",
    "    list_categories_1.append(txt.split(\">>\")[1].strip()) # split du nom par >> et on récupère la première partie\n",
    "\n",
    "# Création d'une nouvelle série catégorie    \n",
    "df[\"category_0\"] = pd.Series(list_categories_0)\n",
    "df[\"category_1\"] = pd.Series(list_categories_1)\n",
    "\n",
    "print(\"Il y a {} catégories de niveau 0 et {} categories de niveau 1\".format(df[\"category_0\"].nunique(), df[\"category_1\"].nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9adbd03",
   "metadata": {},
   "source": [
    "#### Affichage des catégories de niveau 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee580ce-186e-454e-b3ee-5a82371a243b",
   "metadata": {},
   "outputs": [],
   "source": [
    "font_title = {\"weight\": \"bold\",\n",
    "              \"size\": 30}\n",
    "\n",
    "\n",
    "# Liste de couleurs correspondant à chaque catégorie (dans l'ordre de df[\"category_0\"].value_counts().index)\n",
    "colors = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\", \"#8c564b\"]  # adapte la taille selon le nombre de catégories\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "sns.countplot(\n",
    "    data=df, \n",
    "    y=\"category_0\",\n",
    "    order=df[\"category_0\"].value_counts().index,\n",
    "    palette=colors  # applique la liste de couleurs\n",
    ")\n",
    "plt.yticks(size=14)\n",
    "plt.title(f\"Nombre de produits par catégorie de niveau 0\\n\", fontdict=font_title)\n",
    "plt.ylabel(\"product_category level 0\", fontsize=18)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea314d5",
   "metadata": {},
   "source": [
    "#### Affichage des catégories de niveau 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9e1dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 8))\n",
    "sns.countplot(data=df, x=\"category_1\",\n",
    "              edgecolor=\"black\",\n",
    "              order = df['category_1'].value_counts().index,\n",
    "              alpha=0.7)\n",
    "plt.xticks(rotation=90, size=14)\n",
    "plt.title(f\"Nombre de produits par catégorie de niveau 1\\n\",\n",
    "          fontdict=font_title)\n",
    "plt.xlabel('\\n product_category level 1', fontsize=26)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f1b197-8776-429a-bba3-62bc38d5ef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer l'ordre des catégories\n",
    "order = df['category_1'].value_counts().index\n",
    "\n",
    "# Créer une liste de couleurs (à adapter selon le nombre de catégories)\n",
    "colors = sns.color_palette(\"hsv\", len(order))  # palette automatique avec autant de couleurs que de catégories\n",
    "\n",
    "fig = plt.figure(figsize=(18, 8))\n",
    "sns.countplot(\n",
    "    data=df,\n",
    "    x=\"category_1\",\n",
    "    edgecolor=\"black\",\n",
    "    order=order,\n",
    "    alpha=0.7,\n",
    "    palette=colors  # appliquer les couleurs spécifiques\n",
    ")\n",
    "plt.xticks(rotation=90, size=14)\n",
    "plt.title(f\"Nombre de produits par catégorie de niveau 1\\n\", fontdict=font_title)\n",
    "plt.xlabel('\\n product_category level 1', fontsize=26)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b78fb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les catégories utilisés pour la résolution du problème de segmentation\n",
    "categories = df[\"category_0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4151694b",
   "metadata": {},
   "source": [
    "___\n",
    "### **1.5 Descriptif des produits**\n",
    "\n",
    "Nous allons donne un exemple de texte descriptif d'un produit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c29e03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "des = df.loc[df.uniq_id == \"3c4ca34c50a5437a1bcc42b72fc1351f\"]\n",
    "\n",
    "print(\"La catégorie du produit est : {} \\n\".format(des[\"category_0\"].iloc[0]))\n",
    "\n",
    "print(\"La marque du produit est : {} \\n\".format(des[\"brand\"].iloc[0]))\n",
    "\n",
    "print(\"Le nom du produit est : {} \\n\".format(des[\"product_name\"].iloc[0]))\n",
    "\n",
    "print(\"Le descriptif du produit est : \\n \\n {}\".format(des[\"description\"].iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236a4264",
   "metadata": {},
   "source": [
    "___\n",
    "### **1.6 Vérification des doublons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6389bda8-f431-4d73-87a8-3c3ffec0d148",
   "metadata": {},
   "outputs": [],
   "source": [
    "format(len(df)!=df[\"uniq_id\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60fb8d9-56de-4b00-a3ea-24a642c0da7b",
   "metadata": {},
   "source": [
    "Le résultat est **False**, c'est à dire que notre dataset ne contient pas des doublons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51df6f6b",
   "metadata": {},
   "source": [
    "___\n",
    "### **1.7 Concaténation des variables textes : \"product_name\", \"description\" et \"brand\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94110eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_text_data = pd.DataFrame()\n",
    "products_text_data[\"uniq_id\"] = df[\"uniq_id\"]\n",
    "products_text_data[\"category\"] = df[\"category_0\"]\n",
    "products_text_data[\"description\"] = df[\"product_name\"] + \" \"+ df[\"brand\"] + \" \" + df[\"description\"]\n",
    "products_text_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a710faf7",
   "metadata": {},
   "source": [
    "___\n",
    "### **1.8 Les images**\n",
    "\n",
    "#### Affichage d'exemples d'images par catégorie produit de niveau 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614103d3-6b64-4e77-ad0a-1d6a5e577d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import os\n",
    "\n",
    "path = r\"C:\\Users\\hp\\Desktop\\Projet_ML\\Base\\Images\"\n",
    "\n",
    "for j, categ in enumerate(categories.unique()):\n",
    "    print(\"\\033[1m\" + categ + \"\\033[0m\")\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    for i in range(3):\n",
    "        name_image = df[categories == categ][\"image\"].iloc[i]\n",
    "        filename = os.path.join(path, name_image)\n",
    "\n",
    "        if not os.path.exists(filename):\n",
    "            print(f\"❌ Fichier introuvable : {filename}\")\n",
    "            continue\n",
    "\n",
    "        img = imread(filename)\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Exemple {i+1}\", fontsize=10)\n",
    "\n",
    "    plt.suptitle(f\"Catégorie : {categ}\", fontsize=14, weight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45889c95-70d3-462f-9643-ebc0bfbe489f",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#d4f0ff; font-size:20px;padding:20px; border-left:25px solid #1c8adb;\">\n",
    "    <strong> 2. NETTOYAGE ET PRÉ-TRAITEMENT </strong> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734ff664-06cf-4b72-a1eb-bcf492ebf92a",
   "metadata": {},
   "source": [
    "### **2.1 Textes**\n",
    "\n",
    "- Suppression des ponctuations\n",
    "- Tokenization\n",
    "- Suppression des tokens de taille < 2\n",
    "- Suppression des stopwords\n",
    "- Stemming\n",
    "- Lemmatization\n",
    "- Conversion des mots en vecteurs de features (BOW, TF-IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b3d232-5918-4979-8732-adac2b4bd641",
   "metadata": {},
   "source": [
    "### **2.1.1 Suppression des ponctuations**\n",
    "\n",
    "Dans cette étape, nous supprimons tous les signes de ponctuation (tels que ., !, ?, ;, :) présents dans le texte. Cette opération vise à épurer les données textuelles en éliminant les caractères qui n’ont pas de valeur sémantique directe, ce qui simplifie l’analyse et le traitement ultérieur des mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab90bc68-025d-4157-818e-0f9030d3fa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_text_data['removed_punc'] = products_text_data['description'].apply(lambda x: pf.remove_punct(x))\n",
    "products_text_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6724f8d-cde3-4ff3-bcdd-1d218c28e920",
   "metadata": {},
   "source": [
    "#### **2.1.2 Tokenization**\n",
    "\n",
    "Dans cette étape, le texte est segmenté en unités élémentaires appelées tokens, qui correspondent le plus souvent à des mots, mais peuvent également être des phrases ou des caractères selon le niveau de granularité souhaité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce808b4e-c35a-4a46-a8a6-df2d8bc726ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_text_data['tokens'] = products_text_data['removed_punc'].apply(lambda msg : pf.tokenize(msg))\n",
    "products_text_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ee867e-a7f3-40be-8278-37ccca8481c9",
   "metadata": {},
   "source": [
    "#### **2.1.3 Suppression des tokens de taille < 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d726f1cb-da79-42b3-aa40-c284a29482c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_text_data['larger_tokens'] = products_text_data['tokens'].apply(lambda x : pf.remove_small_words(x))\n",
    "products_text_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c13feb-3200-4494-874c-f925736404ee",
   "metadata": {},
   "source": [
    "#### **2.1.4 Suppression des stopwords**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600293a3-c63f-42d1-a2dd-26b325cf6994",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_text_data['clean_tokens'] = products_text_data['larger_tokens'].apply(lambda x : pf.remove_stopwords(x))\n",
    "products_text_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f0ad54-b390-40dd-9e45-82911546bd6a",
   "metadata": {},
   "source": [
    "#### **2.1.5 Stemming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd7e85a-e351-4fe8-9a67-3a83b3663706",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_text_data['stem_words'] = products_text_data['clean_tokens'].apply(lambda wrd: pf.stemming(wrd))\n",
    "products_text_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c383b46d-4215-4b4c-b385-87645d0e354a",
   "metadata": {},
   "source": [
    "#### **2.1.6 Lemmatization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9647e213-f8f7-4834-bea7-034838065a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_text_data['lemma_words'] = products_text_data['clean_tokens'].apply(lambda x : pf.lemmatize(x))\n",
    "products_text_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a2940e-09e8-43e9-9588-475831f3d1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_text_data['clean_text'] = products_text_data['lemma_words'].apply(lambda x : pf.return_sentences(x))\n",
    "products_text_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfff64c7-fda5-4837-a9ab-19176cb1c5b2",
   "metadata": {},
   "source": [
    "#### Texte illustratif avant et après prétraitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60038055-807b-40c8-9887-e2e8e560c622",
   "metadata": {},
   "outputs": [],
   "source": [
    "des = products_text_data.loc[products_text_data.uniq_id == \"3c4ca34c50a5437a1bcc42b72fc1351f\"]\n",
    "print(\"Le descriptif avant prétraitement est : \\n \\n {}\".format(des[\"description\"].iloc[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a082eee3-e39e-474c-ae6c-b58046f0d7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Le descriptif après prétraitement est : \\n \\n {}\".format(des[\"clean_text\"].iloc[0])) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a83b060-3f8f-4c04-9434-cb356e288341",
   "metadata": {},
   "source": [
    "#### Affichage des Top 10 mots les plus fréquents pour chaque catégorie produit de niveau 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8deee7-24fd-4ba8-afcd-4a7db2dbaa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_dfs = pd.DataFrame()\n",
    "\n",
    "for cat1, data_df in products_text_data.groupby(\"category\"):\n",
    "    most_freq_df = pf.get_most_freq(data_df[\"lemma_words\"], 10).reset_index()\n",
    "    most_freq_df[\"Category\"] = cat1\n",
    "    most_freq_dfs = pd.concat([most_freq_dfs, most_freq_df])\n",
    "    pf.plot_freq_dist(most_freq_df, cat1 + \" - FRÉQUENCE DES MOTS (Top 10)\", 10, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9b7465-cc25-446b-bf0f-adfa93227fff",
   "metadata": {},
   "source": [
    "#### Wordclouds par categories produit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7752dc7a-5398-4a19-aa14-87153d94c9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = products_text_data.groupby('category')['clean_text']\n",
    "\n",
    "pf.plot_wordclouds_from_gb(gb, n_top_words=30, n_rows=4, figsize=(15,10),\n",
    "                        backgnd_color='beige', cmap='tab10', random_state=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c07f67-5e61-44cf-82f0-2f20579f69a6",
   "metadata": {},
   "source": [
    "#### **2.1.7 Conversion des mots en vecteurs de features**\n",
    "\n",
    "Nous allons extraire les features en utilisant les méthodes suivantes:\n",
    "\n",
    "- Bag of Words (BOW)\n",
    "- Term Frequency - Inverse Document Frequency (TF-IDF)\n",
    "- Word2Vec\n",
    "\n",
    "Nous allons comparer les résultats obtenus avec chacune de ces transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752acfee-057e-4962-85ca-bb9cc9fb4bf7",
   "metadata": {},
   "source": [
    "##### **2.1.7.1 Transformation en matrice BOW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb53893-a82a-4d19-8f39-099135018a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = CountVectorizer()\n",
    "bow_vect = bow.fit_transform(products_text_data['clean_text']).toarray()\n",
    "bow_vect.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5b8389-25bf-4bc2-a629-9dbc9329c5ec",
   "metadata": {},
   "source": [
    "##### **2.1.7.2 Transformation en matrice TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1551f50-567c-4ac8-935b-7acb77bc2633",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf_vect = tfidf.fit_transform(products_text_data['clean_text']).toarray()\n",
    "tfidf_vect.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b493eeb9-b05c-4175-8c2c-64aef7eecd72",
   "metadata": {},
   "source": [
    "##### **2.1.7.3 Transformation en matrice Word2Vec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebf9c82-7ce3-4f5f-a3f5-bcbad7719e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "data_vec =products_text_data['clean_text']\n",
    "data_token = products_text_data['lemma_words']\n",
    "cores = multiprocessing.cpu_count()\n",
    "text_dim=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffdbba2-982a-4bfd-b9ae-f42d34b2a335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciation du modèle\n",
    "w2v_model_desc_lem = Word2Vec(min_count=20, window=3, size=text_dim,\n",
    "                              sample=6e-5, alpha=0.03, min_alpha=0.0007,\n",
    "                              negative=20, workers=cores-1)\n",
    "# Construit le vocabulaire à partir d'une séquence de mots et\n",
    "# initialise ainsi le modèle.\n",
    "w2v_model_desc_lem.build_vocab(data_token,\n",
    "                               progress_per=10000)\n",
    "# Vectorisation\n",
    "vector_w2v_desc_lem = pf.word2vec_vectorisation(data_vec,\n",
    "                                                        text_dim,\n",
    "                                                        w2v_model_desc_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ae5aa5-9989-4e1b-b81d-097e6751964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_w2v_desc_lem.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8c066d-87e3-4b33-be6d-a6b9eb77c546",
   "metadata": {},
   "source": [
    "### 2.2 Images\n",
    "\n",
    "- **PIL** (Pyhton Imaging Library) et **OpenCV** (Open Compute Vision) sont des librairies qui comprennent un ensemble de méthodes permettant de charger, traiter les images (redimensionnement, filtres...). Ces librairies seront utilisées pour le pré-traitement des images.\n",
    "\n",
    "- Le traitement sera effectué en 5 étapes :\n",
    "    - Correction de l'exposition (étirement d'histogramme) \n",
    "    - Correction du contraste (égalisation d'histogramme)    \n",
    "    - Réduction du bruit (filtre)\n",
    "    - Conversion en niveau de gris     \n",
    "    - Redimensionnement (en 224 * 224)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "74fcc843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>image_loc</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55b85ea15a1536d46b7190ad6fff8ce7.jpg</td>\n",
       "      <td>C:\\Users\\hp\\Desktop\\Projet_ML\\Base\\Images55b85...</td>\n",
       "      <td>Home Furnishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7b72c92c2f6c40268628ec5f14c6d590.jpg</td>\n",
       "      <td>C:\\Users\\hp\\Desktop\\Projet_ML\\Base\\Images7b72c...</td>\n",
       "      <td>Baby Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64d5d4a258243731dc7bbb1eef49ad74.jpg</td>\n",
       "      <td>C:\\Users\\hp\\Desktop\\Projet_ML\\Base\\Images64d5d...</td>\n",
       "      <td>Baby Care</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  image  \\\n",
       "0  55b85ea15a1536d46b7190ad6fff8ce7.jpg   \n",
       "1  7b72c92c2f6c40268628ec5f14c6d590.jpg   \n",
       "2  64d5d4a258243731dc7bbb1eef49ad74.jpg   \n",
       "\n",
       "                                           image_loc         category  \n",
       "0  C:\\Users\\hp\\Desktop\\Projet_ML\\Base\\Images55b85...  Home Furnishing  \n",
       "1  C:\\Users\\hp\\Desktop\\Projet_ML\\Base\\Images7b72c...        Baby Care  \n",
       "2  C:\\Users\\hp\\Desktop\\Projet_ML\\Base\\Images64d5d...        Baby Care  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe de travail pour le traitement des images\n",
    "\n",
    "products_image_data = pd.DataFrame()\n",
    "products_image_data[\"image\"] = df[\"image\"]\n",
    "products_image_data['image_loc'] = [path + row for row in df['image']]\n",
    "products_image_data[\"category\"] = df[\"category_0\"]\n",
    "\n",
    "products_image_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638908e3",
   "metadata": {},
   "source": [
    "___\n",
    "#### **2.1 Illustration du pré-traitement sur une image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7c78ee78",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "dim = (224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ebba89-90bd-4b44-803f-5294e4a999c9",
   "metadata": {},
   "source": [
    "## ***Chargement de l'image originale***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5516655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement de l'image originale comme matrice de pixels\n",
    "img_orig = Image.open(r\"C:\\Users\\hp\\Desktop\\Projet_ML\\Base\\Images\\3c4ca34c50a5437a1bcc42b72fc1351f.jpg\")\n",
    "pf.afficher_image_histopixel(img_orig, 'Image originale')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f850e1-c37e-4bab-9f5a-3ec40fad613b",
   "metadata": {},
   "source": [
    "## ***Correction de l'exposition (étirement d'histogramme)***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd92ce77",
   "metadata": {},
   "source": [
    "- Image sous-exposée ==> histogramme concentré à droite vers les niveaux de gris faible (255 = blanc).\n",
    "- Image sur-exposée ==> histogramme concentré à gauche vers les niveaux de gris fort (0 = noir)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1358418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correction de l'exposition \n",
    "img_expo = ImageOps.autocontrast(img_orig, 1)\n",
    "pf.afficher_image_histopixel(img_expo,'Image après correction de l\\'exposition')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d471773-0845-4025-8538-2c0821d20c40",
   "metadata": {},
   "source": [
    "## ***Correction du contraste (égalisation d'histogramme)***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613639ff",
   "metadata": {},
   "source": [
    "Le contraste caractérise la répartition de lumière dans une image : plus une image est contrastée, plus la différence de luminosité entre ses zones claires et sombres est importante. En général, une image peu contrastée est terne, tandis qu'une image trop contrastée est visuellement \"agressive\". Dans les deux cas, l'image manque de clarté car certains de ses détails seront peu, voire pas du tout,  visibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51723d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correction du contraste\n",
    "img_contr_pils = ImageOps.equalize(img_expo)\n",
    "pf.afficher_image_histopixel(img_contr_pils,'Image après correction du contraste')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e223004-263c-4e22-bfc0-92e03707494c",
   "metadata": {},
   "source": [
    "## ***Réduction du bruit (lissage)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08f89a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réduction du bruit (filtre)\n",
    "\n",
    "img_filter = img_contr_pils.filter(ImageFilter.BoxBlur(1))\n",
    "pf.afficher_image_histopixel(img_filter,'Image après réduction du bruit')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6630f370-51d8-4fb5-bf79-789a77a98480",
   "metadata": {},
   "source": [
    "## ***Convertir l'image en niveau de gris***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c382de5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Conversion de l'image en niveau de gris pour SIFT\n",
    "img_gris = cv.cvtColor(np.array(img_filter), cv.COLOR_RGB2GRAY)\n",
    "pf.afficher_image_histopixel(img_gris,'Image en gris')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa74e64-6230-4c3b-9efc-6be4692451f0",
   "metadata": {},
   "source": [
    "## ***Redimensionnement en 224 * 224***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d664851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redimensionnement image contraste PILS\n",
    "img_redim_pils = cv.resize(np.array(img_gris), dim,\n",
    "                            interpolation=cv.INTER_AREA)\n",
    "pf.afficher_image_histopixel(img_redim_pils,'Image redimensionnée 224*224')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99076db5",
   "metadata": {},
   "source": [
    "___\n",
    "#### **2.2 Pré-traitement de toutes les images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8134443-43c8-4af5-b059-cfa0b4a9a203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-traitement de toutes les images\n",
    "products_image_data['image_proces'] = r\"C:\\Users\\hp\\Desktop\\Projet_ML\\Base\\Images\"\n",
    "products_image_data['image_loc'].apply(pf.preprocess_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "836bd66c-cbf4-4491-9982-109c64203426",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(products_image_data[\"image_loc\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ae8cde01-2754-4bae-b6eb-c6f694c88d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✅] 1050 images manquantes ont été enregistrées dans 'images_manquantes.csv'\n"
     ]
    }
   ],
   "source": [
    "# Vérifier quels fichiers sont réellement absents\n",
    "import os\n",
    "\n",
    "# Ajout d'une colonne indiquant l'existence de l'image\n",
    "products_image_data[\"image_exists\"] = products_image_data[\"image_loc\"].apply(os.path.isfile)\n",
    "\n",
    "# Séparer les lignes avec et sans image\n",
    "images_trouvees = products_image_data[products_image_data[\"image_exists\"] == True]\n",
    "images_manquantes = products_image_data[products_image_data[\"image_exists\"] == False]\n",
    "\n",
    "# Sauvegarde facultative des lignes manquantes\n",
    "images_manquantes.to_csv(\"images_manquantes.csv\", index=False)\n",
    "print(f\"[✅] {len(images_manquantes)} images manquantes ont été enregistrées dans 'images_manquantes.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "262588a2-8692-4d39-892b-b6103576c8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_preprocess(image_path):\n",
    "    try:\n",
    "        return pf.preprocess_image(image_path)\n",
    "    except Exception as e:\n",
    "        print(f\"[⚠️] Erreur pour {image_path} : {e}\")\n",
    "        return None\n",
    "\n",
    "# Appliquer uniquement aux images disponibles\n",
    "images_trouvees[\"image_proces\"] = images_trouvees[\"image_loc\"].apply(safe_preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4f71a137-4000-4313-8a13-8428dba12471",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_image_data = products_image_data.drop(columns=[\"image_proces\"], errors=\"ignore\")\n",
    "products_image_data = products_image_data.merge(\n",
    "    images_trouvees[[\"image_loc\", \"image_proces\"]],\n",
    "    on=\"image_loc\",\n",
    "    how=\"left\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63d4345",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_image_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a9fda9",
   "metadata": {},
   "source": [
    "___\n",
    "#### **2.3 Extraction des features**\n",
    "\n",
    "Nous allons utiliser l'algorithme SIFT (Scale Invariant Feature Transform)\n",
    "\n",
    "La méthodoligie d'extraction de features par SIFT se fait en 3 étapes :\n",
    "\n",
    "- Récupérer les descripteurs de chaque image par un algorithme de type SIFT\n",
    "- Clusteriser l'ensemble de tous les descripteurs\n",
    "- Construction de l'histogramme pour chaque image (Bag of Visual Words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97a10c5",
   "metadata": {},
   "source": [
    "____\n",
    "##### **2.3.1 Extraction des descripteurs sur une image (illustration)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e668da5b-3719-4e77-8a66-d987ad5ccf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mug = cv.imread(r\"C:\\Users\\hp\\Desktop\\Projet_ML\\Base\\Images\\3c4ca34c50a5437a1bcc42b72fc1351f.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823f60d0-e25c-4bf8-94fc-73ef0d2897f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation del'image en matrice de pixels pour OpenCV\n",
    "mug = np.array(mug)\n",
    "\n",
    "# Extraction des keypoints et descripteurs SIFT\n",
    "sift_keypoints, sift_descripteurs = pf.gen_sift_features(mug)\n",
    "\n",
    "print(f\"L'image contient {sift_descripteurs.shape[0]} descripteurs SIFT\")\n",
    "print(f'Chaque descripteur est un vecteur de longueur {sift_descripteurs.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49e372d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des points d'intérêt\n",
    "sift_mug_keypoints = cv.drawKeypoints(mug, sift_keypoints, None)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.grid(False)\n",
    "\n",
    "# Image originale\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.grid(False)\n",
    "plt.title('Image originale')\n",
    "plt.imshow(mug)\n",
    "\n",
    "# Image avec les points clés\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.grid(False)\n",
    "plt.imshow(sift_mug_keypoints)\n",
    "plt.title('SIFT Points clés')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa4e775",
   "metadata": {},
   "source": [
    "___\n",
    "##### **2.3.3 Etape 1: Extraction des descripteurs SIFT sur l'ensemble des images**\n",
    "\n",
    "Nous détectons les features, extrayons les descripteurs de chaque image du dataset et construisons un dictionnaire visuel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa3a7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des images pré-traitées dans le dictionnaire images\n",
    "images = pf.load_image_in_dict(r\"C:\\Users\\hp\\Desktop\\Projet_ML\\Base\\Images\")\n",
    "print(f'{len(images)} images chargées')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3893970-2709-413a-b2d5-120bb5fcf67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Chemin vers l'image d'origine\n",
    "input_path = r\"C:\\Users\\hp\\Desktop\\Projet_ML\\Base\\Images\\5518124b75d6c6dfee4c2e4c0cfa716a.jpg\"\n",
    "\n",
    "# Chemin vers l'image redimensionnée\n",
    "output_path = r\"C:\\Users\\hp\\Desktop\\Projet_ML\\Base\\Images\\resized_5518124b75d6c6dfee4c2e4c0cfa716a.jpg\"\n",
    "\n",
    "# Taille maximale (tu peux ajuster si besoin)\n",
    "max_size = (1024, 1024)\n",
    "\n",
    "try:\n",
    "    # Ouvrir l’image\n",
    "    img = Image.open(input_path)\n",
    "\n",
    "    # Redimensionner en gardant les proportions\n",
    "    img.thumbnail(max_size, Image.LANCZOS)\n",
    "\n",
    "    # Sauvegarder l’image redimensionnée\n",
    "    img.save(output_path)\n",
    "\n",
    "    print(f\"[✅] Image redimensionnée enregistrée à : {output_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"[❌] Image introuvable : {input_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"[❌] Erreur lors du redimensionnement : {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6de9530-7059-4696-a6ee-8c19a04474cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sifts = pf.sift_features_batch(images, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f09288e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraction des descripteurs SIFT\n",
    "#sifts = pf.sift_features(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c389ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des descripteurs\n",
    "descriptor_list = sifts[0] \n",
    "# Liste des vecteurs par images (dictionnaires clé=nom_image, vecteur)\n",
    "all_bovw_feature = sifts[1]\n",
    "\n",
    "print(\"Nombre de descripteurs : \", len(descriptor_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25beaea",
   "metadata": {},
   "source": [
    "___\n",
    "##### **2.3.4 Etape 2: Clustering des descripteurs**\n",
    "\n",
    "Ensuite, nous créons des clusters à partir des descripteurs (avec K-Means). Le centre de chaque cluster sera utilisé comme vocabulaire du dictionnaire visuel.\n",
    "\n",
    "Une règle empirique consiste à créer k clusters avec k = nombre de catégories * 10 (dans notre cas, c'est 70)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a10ab8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLUSTERS = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6435b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupère les centres de clusters qui sont les mots visuels    \n",
    "visual_words = pf.kmeans(N_CLUSTERS, descriptor_list) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540a84dd",
   "metadata": {},
   "source": [
    "____\n",
    "##### **2.3.5 Etape 3: Construction de l'histogramme pour chaque image (Bag of Visual Words)** \n",
    "\n",
    "Enfin, pour chaque image, on fait un histogramme de fréquence à partir des vocabulaires (les centres des clusters obtenus à l'étape précédente) et de la fréquence des vocabulaires dans l'image. Ces histogrammes sont nos sacs de mots visuels (BOVW)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce3ac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des histogrammes  \n",
    "bovw = pf.image_class(all_bovw_feature, visual_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e0ccbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe de sauvegarde des BOVW SIFT\n",
    "df_bovw = pd.DataFrame({'image': bovw.keys(),'sift_bovw': bovw.values()})\n",
    "# Ajout des BOVW en np.array d'une liste\n",
    "df_bovw['Histo'] = [row[0] for row in df_bovw['sift_bovw']]\n",
    "# Ajout de la catégorie\n",
    "df_bovw = df_bovw.merge(products_image_data[['image', 'image_loc','category']], how='left', on='image')\n",
    "\n",
    "df_bovw.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bb1a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La matrice des histogrammes\n",
    "hist_vectors=[]\n",
    "for key,value in bovw.items():\n",
    "    hist_vectors.append(value[0])\n",
    "    \n",
    "im_features = np.asarray(hist_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e77ef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184575ef",
   "metadata": {},
   "source": [
    "**Visualisation de l'histogramme pour notre image exemple**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d91f6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération de l'historgramme\n",
    "df_visu = df_bovw[df_bovw['image'] ==\n",
    "                       '3c4ca34c50a5437a1bcc42b72fc1351f.jpg']['sift_bovw']\n",
    "histo_mug = df_visu.to_list()[0][0]\n",
    "plt.figure(figsize=(20, 7))\n",
    "plt.title('SIFT Histogramme Image Mug en exemple', fontsize=30)\n",
    "plt.xlabel(\"SIFT Visual words\", fontsize=24)\n",
    "plt.ylabel(\"Fréquence des VW\", fontsize=24)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.grid(False)\n",
    "plt.plot(histo_mug)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b71932d-aaaa-4be1-9db9-f9ab1835466e",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#d4f0ff; font-size:20px;padding:20px; border-left:25px solid #1c8adb;\">\n",
    "    <strong> 3. REDUCTION DE DIMENSION </strong> \n",
    "</div>\n",
    "\n",
    "Nous allons utiliser 2 techniques :\n",
    "- Analyse en Composantes Principales (ACP)\n",
    "- t-distributed stochastic neighbor embedding (t-SNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd708ad6-f418-47b3-9447-d3f8b02b547a",
   "metadata": {},
   "source": [
    "### 3.1 Textes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28732bb4-4d71-4dfe-b0d5-bd6e79836327",
   "metadata": {},
   "source": [
    "Les matrices BOW et TF-IDF donnent des matrices creuses et imposantes. \n",
    "\n",
    "Une réduction dimensionnelle pourra aider à \"condenser\" ces matrices en faisant ressortir de nouvelles features qui \"résumeront\" les features initiales. \n",
    "\n",
    "Cela nous permettra par la suite de visualiser ces jeux de données, tout en réduisant les temps de calcul."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a2e56f-deed-4a59-b775-d4282734d9cb",
   "metadata": {},
   "source": [
    "#### 3.1.1 PCA\n",
    "\n",
    "La réduction PCA permet de créer des features décorrélées entre elles, et de diminuer leur dimension, tout en gardant un niveau de variance expliquée élevé (99% dans notre cas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f446e12-4d2c-4d5f-8c57-1184cf84d9dd",
   "metadata": {},
   "source": [
    "##### 3.1.1.1 BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90007b86-71e8-48b0-9977-8ddc47422b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dimensions dataset avant réduction PCA : \", bow_vect.shape)\n",
    "pca = decomposition.PCA(n_components=0.99)\n",
    "pca_results_bow= pca.fit_transform(bow_vect)\n",
    "print(\"Dimensions dataset après réduction PCA : \", pca_results_bow.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2e6dba-9390-44de-8263-afada9c3e74c",
   "metadata": {},
   "source": [
    "##### 3.1.1.2 TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ecdf81-cbce-4001-ae8e-335ed4db1fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dimensions dataset avant réduction PCA : \", tfidf_vect.shape)\n",
    "pca = decomposition.PCA(n_components=0.99)\n",
    "pca_results_tfidf= pca.fit_transform(tfidf_vect)\n",
    "print(\"Dimensions dataset après réduction PCA : \", pca_results_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38c969e-766c-4e7e-abbe-654696c9fd75",
   "metadata": {},
   "source": [
    "##### 3.1.1.3 Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8ab372-3dea-4210-9f73-89350cc5c282",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dimensions dataset avant réduction PCA : \", vector_w2v_desc_lem.shape)\n",
    "pca = decomposition.PCA(n_components=0.99)\n",
    "pca_results_word2vec= pca.fit_transform(vector_w2v_desc_lem)\n",
    "print(\"Dimensions dataset après réduction PCA : \", pca_results_word2vec.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c825cc13-3917-4138-ac61-08627999f63f",
   "metadata": {},
   "source": [
    "#### 3.1.2 TSNE\n",
    "\n",
    "Réduction de dimension en 2 composantes T-SNE pour affichage en 2D des textes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee063ad4-c9a9-4efc-ada6-95576830c662",
   "metadata": {},
   "source": [
    "##### 3.1.2.1 BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94d9e52-2527-4dd2-9f93-0d3047221811",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = manifold.TSNE(n_components=2, perplexity=30, \n",
    "                     n_iter=2000, init='random', random_state=6)\n",
    "tsne_results_bow = tsne.fit_transform(pca_results_bow)\n",
    "\n",
    "df_tsne_bow = pd.DataFrame(tsne_results_bow[:,0:2], columns=['tsne1', 'tsne2'])\n",
    "df_tsne_bow[\"class\"] = products_text_data[\"category\"]\n",
    "print(df_tsne_bow.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7637aa69-df9f-469f-83e4-638f0108ab26",
   "metadata": {},
   "source": [
    "##### 3.1.2.2 TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66aa3c7-d7e3-4d38-96b1-a730ef25c38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = manifold.TSNE(n_components=2, perplexity=30, \n",
    "                     n_iter=2000, init='random', random_state=6)\n",
    "tsne_results_tfidf = tsne.fit_transform(pca_results_tfidf)\n",
    "\n",
    "df_tsne_tfidf = pd.DataFrame(tsne_results_tfidf[:,0:2], columns=['tsne1', 'tsne2'])\n",
    "df_tsne_tfidf[\"class\"] = products_text_data[\"category\"]\n",
    "print(df_tsne_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7e2196-a8f8-4255-a7ca-56c3de70218d",
   "metadata": {},
   "source": [
    "##### 3.1.2.3 Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2696df72-4930-49e6-9fc8-81f20e8d6ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = manifold.TSNE(n_components=2, perplexity=30, \n",
    "                     n_iter=2000, init='random', random_state=6)\n",
    "tsne_results_word2vec = tsne.fit_transform(pca_results_word2vec)\n",
    "\n",
    "df_tsne_word2vec = pd.DataFrame(tsne_results_word2vec[:,0:2], columns=['tsne1', 'tsne2'])\n",
    "df_tsne_word2vec[\"class\"] = products_text_data[\"category\"]\n",
    "print(df_tsne_word2vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81caa41e-f070-4605-beb1-d617bdb9a9b5",
   "metadata": {},
   "source": [
    "#### 3.1.3 Visualisation\n",
    "\n",
    "Affichage T-SNE selon les catégories d'images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c455680-c110-4440-94b3-63e67a8ca5a5",
   "metadata": {},
   "source": [
    "##### 3.1.3.1 BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cf6e20-a6ac-458d-828a-52a6177f13d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.scatterplot(\n",
    "    x=\"tsne1\", y=\"tsne2\", hue=\"class\", data=df_tsne_bow, legend=\"brief\",\n",
    "    palette=sns.color_palette('tab10', n_colors=7), s=50, alpha=0.8)\n",
    "\n",
    "plt.title('TSNE (BOW) selon les catégories produit', fontsize = 30, pad = 35, fontweight = 'bold')\n",
    "plt.xlabel('tsne1', fontsize = 26, fontweight = 'bold')\n",
    "plt.ylabel('tsne2', fontsize = 26, fontweight = 'bold')\n",
    "plt.legend(prop={'size': 14}) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe3aa3b-5906-498b-bac0-dc72ea9f0d12",
   "metadata": {},
   "source": [
    "##### 3.1.3.2 TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9014194-4c48-47b5-b4a0-811af9d3424e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.scatterplot(\n",
    "    x=\"tsne1\", y=\"tsne2\", hue=\"class\", data=df_tsne_tfidf, legend=\"brief\",\n",
    "    palette=sns.color_palette('tab10', n_colors=7), s=50, alpha=0.8)\n",
    "\n",
    "plt.title('TSNE (TF-IDF) selon les catégories produit', fontsize = 30, pad = 35, fontweight = 'bold')\n",
    "plt.xlabel('tsne1', fontsize = 26, fontweight = 'bold')\n",
    "plt.ylabel('tsne2', fontsize = 26, fontweight = 'bold')\n",
    "plt.legend(prop={'size': 14}) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb87b4b-d270-42df-bd7a-3276999feb0f",
   "metadata": {},
   "source": [
    "##### 3.1.3.3 Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96517eab-388b-410d-84f4-42cdba5ec317",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.scatterplot(\n",
    "    x=\"tsne1\", y=\"tsne2\", hue=\"class\", data=df_tsne_word2vec, legend=\"brief\",\n",
    "    palette=sns.color_palette('tab10', n_colors=7), s=50, alpha=0.8)\n",
    "\n",
    "plt.title('TSNE (Word2Vec) selon les catégories produit', fontsize = 30, pad = 35, fontweight = 'bold')\n",
    "plt.xlabel('tsne1', fontsize = 26, fontweight = 'bold')\n",
    "plt.ylabel('tsne2', fontsize = 26, fontweight = 'bold')\n",
    "plt.legend(prop={'size': 14}) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ffd325-2286-446b-9804-4575bf4f62ed",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "- Les affichages des données textes (à partir TF-IDF et Word2Vec) permettent de mieux observer une sorte de regroupement des points appartenant à la même catégorie produit. \n",
    "- On observe même qu'avec les feaures construits avec TF-IDF, les points appartenant à la catégorie *Watches* sont très bien regroupés et le groupe est bien séparé des autres groupes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56c5bd2-102a-4bdf-aee6-e6a13f499cf4",
   "metadata": {},
   "source": [
    "### 3.2 Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3060f3",
   "metadata": {},
   "source": [
    "___\n",
    "#### **3.1 PCA**\n",
    "\n",
    "La réduction PCA permet de créer des features décorrélées entre elles, et de diminuer leur dimension, tout en gardant un niveau de variance expliquée élevé (99% dans notre cas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "85335478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions dataset avant réduction PCA :  (1050, 70)\n",
      "Dimensions dataset après réduction PCA :  (1050, 59)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions dataset avant réduction PCA : \", im_features.shape)\n",
    "pca = decomposition.PCA(n_components=0.99)\n",
    "pca_results_img = pca.fit_transform(im_features)\n",
    "print(\"Dimensions dataset après réduction PCA : \", pca_results_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336d3721",
   "metadata": {},
   "source": [
    "___\n",
    "#### **3.2 TSNE**\n",
    "\n",
    "Réduction de dimension en 2 composantes T-SNE pour affichage en 2D des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88760ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = manifold.TSNE(n_components=2, perplexity=30, \n",
    "                     n_iter=2000, init='random', random_state=6)\n",
    "tsne_results_img = tsne.fit_transform(pca_results_img)\n",
    "\n",
    "df_tsne_img = pd.DataFrame(tsne_results_img[:,0:2], columns=['tsne1', 'tsne2'])\n",
    "df_tsne_img[\"class\"] = products_image_data[\"category\"]\n",
    "print(df_tsne_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07ae53c",
   "metadata": {},
   "source": [
    "___\n",
    "#### **3.3 Visualisation**\n",
    "\n",
    "Affichage T-SNE selon les catégories d'images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41260d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.scatterplot(\n",
    "    x=\"tsne1\", y=\"tsne2\", hue=\"class\", data=df_tsne_img, legend=\"brief\",\n",
    "    palette=sns.color_palette('tab10', n_colors=7), s=50, alpha=0.8)\n",
    "\n",
    "plt.title('TSNE(SIFT) selon les catégories produit', fontsize = 30, pad = 35, fontweight = 'bold')\n",
    "plt.xlabel('tsne1', fontsize = 26, fontweight = 'bold')\n",
    "plt.ylabel('tsne2', fontsize = 26, fontweight = 'bold')\n",
    "plt.legend(prop={'size': 14}) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1ab120",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "Le regroupement par catégories produits est moins perceptible que ce qu'on a pu observer sur les données textuelles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c8b29d-1820-4297-8acb-983732f2a9c9",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#d4f0ff; font-size:20px;padding:20px; border-left:25px solid #1c8adb;\">\n",
    "    <strong> 4. CLUSTERING </strong> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a989de0-aee9-4aa9-a766-ec9f23e9ad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLUSTERS = 7 # On a 7 catégories produit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077830ae-17de-442b-8b1d-6132a1a94d1a",
   "metadata": {},
   "source": [
    "### 4.1 Textes\n",
    "\n",
    "La visualisation t-SNE sur les features TF-IDF et Word2Vec ayant permis d'observer un meilleur regroupement des catégories, ce sont ces features que nous conserverons pour le clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142f3a97-1a08-41ad-8b86-d4c5428d2fb1",
   "metadata": {},
   "source": [
    "#### 4.1.1 TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2f559b-c3cf-47bc-9419-e52978743cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création de clusters à partir du T-SNE \n",
    "X = df_tsne_tfidf[[\"tsne1\",\"tsne2\"]]\n",
    "\n",
    "cls = KMeans(n_clusters=N_CLUSTERS, init='k-means++', random_state=0)\n",
    "cls.fit(X)\n",
    "\n",
    "df_tsne_tfidf[\"cluster\"] = cls.labels_\n",
    "\n",
    "sil = silhouette_score(X,cls.labels_,metric=\"euclidean\")\n",
    "print(\"Le score de silhouette est\", sil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b30e9c8-6516-426e-b9e6-3aaae51e4052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des labels à partir du nom de catégorie produit\n",
    "le = preprocessing.LabelEncoder()\n",
    "products_text_data[\"label\"] = le.fit_transform(products_text_data[\"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33001a8-01c8-4010-8fa3-17d80ad7bf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df0f3d6-feca-4f12-8bdf-59bd9eb24a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_labels = [\"Baby Care\", \"Beauty and Personal Care\", \"Computers\", \"Home Decor & Festive Needs\", \"Home Furnishing\", \"Kitchen & Dining\", \"Watches\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03be1aa5-86a5-4f4a-bb8c-9c615c7a2275",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affichage des images selon clusters et calcul ARI de similarité catégories produit / clusters\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.scatterplot(\n",
    "    x=\"tsne1\", y=\"tsne2\",\n",
    "    hue=\"cluster\",\n",
    "    palette=sns.color_palette('tab10', n_colors=7), s=50, alpha=0.8,\n",
    "    data=df_tsne_tfidf,\n",
    "    legend=\"brief\")\n",
    "\n",
    "plt.title('TSNE (TF-IDF) selon les clusters', fontsize = 30, pad = 35, fontweight = 'bold')\n",
    "plt.xlabel('tsne1', fontsize = 26, fontweight = 'bold')\n",
    "plt.ylabel('tsne2', fontsize = 26, fontweight = 'bold')\n",
    "plt.legend(prop={'size': 14}) \n",
    "\n",
    "plt.show()\n",
    "\n",
    "labels = products_text_data[\"label\"]\n",
    "print(\"ARI : \", metrics.adjusted_rand_score(labels, cls.labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575349b1-7c5f-4ebc-94bb-f090b411fea1",
   "metadata": {},
   "source": [
    "**Qualité de la catégorisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac66db9-cba1-475c-bcbc-1776469f5cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tsne_tfidf.groupby(\"cluster\").count()[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1be01aa-478a-449d-9e17-6d39321e5be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.plot_stacked_bar_clust_vs_cat(df_tsne_tfidf[\"cluster\"],\n",
    "                              df_tsne_tfidf[\"class\"],\n",
    "                              df_tsne_tfidf,   \n",
    "                              palette='tab10',\n",
    "                              figsize=(7,4),\n",
    "                              bboxtoanchor=(1,1), ylim=(0,250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5146b59d-967a-4f00-84e6-efd3825ca2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_clust_confmat = pf.plot_conf_matrix_cat_vs_clust(df_tsne_tfidf['class'],\n",
    "                                                  df_tsne_tfidf['cluster'],\n",
    "                                                  normalize=False,\n",
    "                                                  margins_sums=True,\n",
    "                                                  margins_score=True)\n",
    "with pd.option_context('display.float_format', '{:.0f}'.format):\n",
    "    display(cat_clust_confmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c8a3d2-0070-4db6-9546-4ad30ab49e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affiche la matrice de confusion (Vraies catégories vs. Clusters)\n",
    "\n",
    "cm = pf.plot_conf_matrix_cat_vs_clust(df_tsne_tfidf['class'],\n",
    "                            df_tsne_tfidf['cluster'],\n",
    "                            normalize=False,\n",
    "                            margins_sums=False,\n",
    "                            margins_score=False)\n",
    "pf.plot_heatmap(cm, \"Confusion matrix | true categories vs. clusters\",\n",
    "             figsize=(8, 4), vmin=0, vmax=150, center=75,\n",
    "                 palette=sns.color_palette(\"viridis\", 20), shape='rect',\n",
    "                 fmt='.0f', robust=False, fig=None, ax=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabb54cf-7608-4777-ac4c-388fbda5486f",
   "metadata": {},
   "source": [
    "#### 4.1.2 Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f003f0a2-bcd4-4dd9-ab40-6dfacd01a375",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création de clusters à partir du T-SNE \n",
    "X = df_tsne_word2vec[[\"tsne1\",\"tsne2\"]]\n",
    "\n",
    "cls = KMeans(n_clusters=N_CLUSTERS, init='k-means++', random_state=0)\n",
    "cls.fit(X)\n",
    "\n",
    "df_tsne_word2vec[\"cluster\"] = cls.labels_\n",
    "\n",
    "sil = silhouette_score(X,cls.labels_,metric=\"euclidean\")\n",
    "print(\"Le score de silhouette est\", sil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c473e237-32b7-4705-9427-b791ea9b4594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affichage des images selon clusters et calcul ARI de similarité catégories images / clusters\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.scatterplot(\n",
    "    x=\"tsne1\", y=\"tsne2\",\n",
    "    hue=\"cluster\",\n",
    "    palette=sns.color_palette('tab10', n_colors=7), s=50, alpha=0.8,\n",
    "    data=df_tsne_word2vec,\n",
    "    legend=\"brief\")\n",
    "\n",
    "plt.title('TSNE (Word2Vec) selon les clusters', fontsize = 30, pad = 35, fontweight = 'bold')\n",
    "plt.xlabel('tsne1', fontsize = 26, fontweight = 'bold')\n",
    "plt.ylabel('tsne2', fontsize = 26, fontweight = 'bold')\n",
    "plt.legend(prop={'size': 14}) \n",
    "\n",
    "plt.show()\n",
    "\n",
    "labels = products_text_data[\"label\"]\n",
    "print(\"ARI : \", metrics.adjusted_rand_score(labels, cls.labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec30e28-ea33-4fb7-b154-1c2d4610c654",
   "metadata": {},
   "source": [
    "**Qualité de la catégorisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4226de46-a840-4416-82fa-1a91d7a0f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tsne_word2vec.groupby(\"cluster\").count()[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313ed749-7bda-48a4-b122-c539bc4d5a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.plot_stacked_bar_clust_vs_cat(df_tsne_word2vec[\"cluster\"],\n",
    "                              df_tsne_word2vec[\"class\"],\n",
    "                              df_tsne_word2vec,   \n",
    "                              palette='tab10',\n",
    "                              figsize=(7,4),\n",
    "                              bboxtoanchor=(1,1), ylim=(0,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fe1c19-d6a4-40e2-bd66-3c37cfa9a274",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_clust_confmat = pf.plot_conf_matrix_cat_vs_clust(df_tsne_word2vec['class'],\n",
    "                                                  df_tsne_word2vec['cluster'],\n",
    "                                                  normalize=False,\n",
    "                                                  margins_sums=True,\n",
    "                                                  margins_score=True)\n",
    "with pd.option_context('display.float_format', '{:.0f}'.format):\n",
    "    display(cat_clust_confmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a67555-74c7-4cf7-aa10-a66cc5a51598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affiche la matrice de confusion (Vraies catégories vs. Clusters)\n",
    "\n",
    "cm = pf.plot_conf_matrix_cat_vs_clust(df_tsne_word2vec['class'],\n",
    "                            df_tsne_word2vec['cluster'],\n",
    "                            normalize=False,\n",
    "                            margins_sums=False,\n",
    "                            margins_score=False)\n",
    "pf.plot_heatmap(cm, \"Confusion matrix | true categories vs. clusters\",\n",
    "             figsize=(8, 4), vmin=0, vmax=150, center=75,\n",
    "                 palette=sns.color_palette(\"viridis\", 20), shape='rect',\n",
    "                 fmt='.0f', robust=False, fig=None, ax=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28490006-5c8d-4464-9c24-9c4591e6ff25",
   "metadata": {},
   "source": [
    "**Recap**\n",
    "\n",
    "*TF-IDF*\n",
    "\n",
    "- ARI = 0.59\n",
    "- Silhouette = 0.48\n",
    "- 220 erreurs de catégorisation\n",
    "\n",
    "*Word2Vec*\n",
    "\n",
    "- ARI = 0.34\n",
    "- Silhouette = 0.45\n",
    "- 485 erreurs de catégorisation\n",
    "\n",
    "**Observation générale**\n",
    "- les scores ARI et de silhouette sont plutôt moyennement bons sur les features textuels.\n",
    "- ce qui suggère qu'une classification des produits à partir des données textuelles serait plutôt faisable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbb161c-85c1-4551-a575-93f8e41ceca7",
   "metadata": {},
   "source": [
    "### 4.2 Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c31f407",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création de clusters à partir du T-SNE \n",
    "X = df_tsne_img[[\"tsne1\",\"tsne2\"]]\n",
    "\n",
    "cls = KMeans(n_clusters=N_CLUSTERS, init='k-means++', random_state=0)\n",
    "cls.fit(X)\n",
    "\n",
    "df_tsne_img[\"cluster\"] = cls.labels_\n",
    "\n",
    "sil = silhouette_score(X,cls.labels_,metric=\"euclidean\")\n",
    "print(\"Le score de silhouette est\", sil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9aa100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des labels à partir du nom de catégory produit\n",
    "products_image_data[\"label\"] = le.fit_transform(products_image_data[\"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac52944",
   "metadata": {},
   "outputs": [],
   "source": [
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250f610b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affichage des images selon clusters et calcul ARI de similarité catégories images / clusters\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.scatterplot(\n",
    "    x=\"tsne1\", y=\"tsne2\",\n",
    "    hue=\"cluster\",\n",
    "    palette=sns.color_palette('tab10', n_colors=7), s=50, alpha=0.8,\n",
    "    data=df_tsne_img,\n",
    "    legend=\"brief\")\n",
    "\n",
    "plt.title('TSNE (SIFT) selon les clusters', fontsize = 30, pad = 35, fontweight = 'bold')\n",
    "plt.xlabel('tsne1', fontsize = 26, fontweight = 'bold')\n",
    "plt.ylabel('tsne2', fontsize = 26, fontweight = 'bold')\n",
    "plt.legend(prop={'size': 14}) \n",
    "\n",
    "plt.show()\n",
    "\n",
    "labels = products_image_data[\"label\"]\n",
    "print(\"ARI : \", metrics.adjusted_rand_score(labels, cls.labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4546ca2d",
   "metadata": {},
   "source": [
    "**Observations** \n",
    "- le score ARI est très mauvais\n",
    "- le score de silhouette est moins bon que celui obtenu sur les données textes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227e0264",
   "metadata": {},
   "source": [
    "**Qualité de la catégorisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f267007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tsne_img.groupby(\"cluster\").count()[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d635a1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.plot_stacked_bar_clust_vs_cat(df_tsne_img[\"cluster\"],\n",
    "                              df_tsne_img[\"class\"],\n",
    "                              df_tsne_img,   \n",
    "                              palette='tab10',\n",
    "                              figsize=(7,4),\n",
    "                              bboxtoanchor=(1,1), ylim=(0,250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "35fe9a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>cluster</th>\n",
       "      <th>6</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>2</th>\n",
       "      <th>cat_sum</th>\n",
       "      <th>cat_matching_score_pct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baby Care</th>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>150</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beauty and Personal Care</th>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>150</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Computers</th>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>150</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Home Decor &amp; Festive Needs</th>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>33</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>150</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Home Furnishing</th>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>150</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kitchen &amp; Dining</th>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>31</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>150</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Watches</th>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>150</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clust_sum</th>\n",
       "      <td>120</td>\n",
       "      <td>145</td>\n",
       "      <td>151</td>\n",
       "      <td>175</td>\n",
       "      <td>196</td>\n",
       "      <td>150</td>\n",
       "      <td>113</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clust_matching_score_pct</th>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "cluster                      6   0   1   3   4   5   2 cat_sum  \\\n",
       "class                                                            \n",
       "Baby Care                   24  16  27  24  22  21  16     150   \n",
       "Beauty and Personal Care    16  26  17  29  30  17  15     150   \n",
       "Computers                   15  25  23  21  30  23  13     150   \n",
       "Home Decor & Festive Needs  16  23  25  33  22  17  14     150   \n",
       "Home Furnishing             13  19  20  26  30  23  19     150   \n",
       "Kitchen & Dining            18  19  19  21  31  26  16     150   \n",
       "Watches                     18  17  20  21  31  23  20     150   \n",
       "clust_sum                  120 145 151 175 196 150 113       -   \n",
       "clust_matching_score_pct    20  18  15  19  15  17  18       -   \n",
       "\n",
       "cluster                    cat_matching_score_pct  \n",
       "class                                              \n",
       "Baby Care                                      16  \n",
       "Beauty and Personal Care                       17  \n",
       "Computers                                      15  \n",
       "Home Decor & Festive Needs                     22  \n",
       "Home Furnishing                                20  \n",
       "Kitchen & Dining                               17  \n",
       "Watches                                        13  \n",
       "clust_sum                                       -  \n",
       "clust_matching_score_pct                        -  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cat_clust_confmat = pf.plot_conf_matrix_cat_vs_clust(df_tsne_img['class'],\n",
    "                                                  df_tsne_img['cluster'],\n",
    "                                                  normalize=False,\n",
    "                                                  margins_sums=True,\n",
    "                                                  margins_score=True)\n",
    "with pd.option_context('display.float_format', '{:.0f}'.format):\n",
    "    display(cat_clust_confmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bb40c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affiche la matrice de confusion (Vraies catégories vs. Clusters)\n",
    "\n",
    "cm = pf.plot_conf_matrix_cat_vs_clust(df_tsne_img['class'],\n",
    "                            df_tsne_img['cluster'],\n",
    "                            normalize=False,\n",
    "                            margins_sums=False,\n",
    "                            margins_score=False)\n",
    "pf.plot_heatmap(cm, \"Confusion matrix | true categories vs. clusters\",\n",
    "             figsize=(8, 4), vmin=0, vmax=150, center=75,\n",
    "                 palette=sns.color_palette(\"viridis\", 20), shape='rect',\n",
    "                 fmt='.0f', robust=False, fig=None, ax=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbfb97c",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "- ARI = -0.00019\n",
    "- Silhouette = 0.37\n",
    "- 867 erreurs de catégorisation\n",
    "\n",
    "Les catégorisation avec les features SIFT ne permet pas vraiment de retrouver les vraies catégories produit (score ARI très mauvais)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866d9a7b",
   "metadata": {},
   "source": [
    "___\n",
    "## 5. CONCLUSION\n",
    "\n",
    "- L'utilisation des données texte (features TF-IDF) permet une meilleur catégorisation des produits par rapport aux données image.\n",
    "- La classification avec les données images pouraient certainement être améliorée en utilisant un algorithme de type CNN (Transfer Learning). Nous allons le tester dans la section ANNEXE\n",
    "\n",
    ">**Nous validons la faisabilité de la mise en oeuvre d'un moteur de classification automatique des produits**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b314c6da",
   "metadata": {},
   "source": [
    "___\n",
    "## 6. ANNEXE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ea229",
   "metadata": {},
   "source": [
    "### 6.1  EXPLORATION DES TOPICS\n",
    "\n",
    "On va tester 2 approches non supervisées, afin de voir si les topics abordés dans les documents permettraient de classifier un produit : \n",
    "- Latent Dirichlet Allocation (LDA)\n",
    "- Negative Matrix Factorization (NMF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaebc70",
   "metadata": {},
   "source": [
    "#### 6.1.1 Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "934ed254",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = 7\n",
    "n_top_words = 10\n",
    "\n",
    "# Créer le modèle LDA\n",
    "lda = LatentDirichletAllocation(n_components=n_topics, \n",
    "                                max_iter=5, \n",
    "                                learning_method='online', \n",
    "                                learning_offset=50,\n",
    "                                random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea0067f",
   "metadata": {},
   "source": [
    "##### 6.1.1.1 Données Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf63b8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitter sur les données\n",
    "lda.fit(bow_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316a4de2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Catégories in LDA model (BOW):\")\n",
    "bow_feature_names = bow.get_feature_names()\n",
    "\n",
    "pf.print_top_words(lda, bow_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509fa7a0",
   "metadata": {},
   "source": [
    "Analysons les proportions de produits des différentes catégories connues pour chaque topic, afin de voir s'il est possible de faire des couples (catégorie, topic) uniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b486a560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>% Home Furnishing</th>\n",
       "      <th>% Baby Care</th>\n",
       "      <th>% Watches</th>\n",
       "      <th>% Home Decor &amp; Festive Needs</th>\n",
       "      <th>% Kitchen &amp; Dining</th>\n",
       "      <th>% Beauty and Personal Care</th>\n",
       "      <th>% Computers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>1.111111</td>\n",
       "      <td>52.222222</td>\n",
       "      <td>7.222222</td>\n",
       "      <td>3.888889</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>13.888889</td>\n",
       "      <td>16.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>31.250000</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>6.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>85.714286</td>\n",
       "      <td>14.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.692308</td>\n",
       "      <td>23.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>17.948718</td>\n",
       "      <td>35.897436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>32.773109</td>\n",
       "      <td>7.983193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.369748</td>\n",
       "      <td>29.411765</td>\n",
       "      <td>3.361345</td>\n",
       "      <td>2.100840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>12.406015</td>\n",
       "      <td>5.827068</td>\n",
       "      <td>24.060150</td>\n",
       "      <td>14.661654</td>\n",
       "      <td>8.834586</td>\n",
       "      <td>18.796992</td>\n",
       "      <td>15.413534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.263158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.894737</td>\n",
       "      <td>31.578947</td>\n",
       "      <td>7.894737</td>\n",
       "      <td>47.368421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       % Home Furnishing  % Baby Care  % Watches  \\\n",
       "Topic                                              \n",
       "0.0             1.111111    52.222222   7.222222   \n",
       "1.0            25.000000     6.250000   0.000000   \n",
       "2.0             0.000000     0.000000   0.000000   \n",
       "3.0             0.000000     7.692308  23.076923   \n",
       "4.0            32.773109     7.983193   0.000000   \n",
       "5.0            12.406015     5.827068  24.060150   \n",
       "6.0             0.000000     5.263158   0.000000   \n",
       "\n",
       "       % Home Decor & Festive Needs  % Kitchen & Dining  \\\n",
       "Topic                                                     \n",
       "0.0                        3.888889            5.555556   \n",
       "1.0                       25.000000           31.250000   \n",
       "2.0                        0.000000            0.000000   \n",
       "3.0                        0.000000           15.384615   \n",
       "4.0                       24.369748           29.411765   \n",
       "5.0                       14.661654            8.834586   \n",
       "6.0                        7.894737           31.578947   \n",
       "\n",
       "       % Beauty and Personal Care  % Computers  \n",
       "Topic                                           \n",
       "0.0                     13.888889    16.111111  \n",
       "1.0                      6.250000     6.250000  \n",
       "2.0                     85.714286    14.285714  \n",
       "3.0                     17.948718    35.897436  \n",
       "4.0                      3.361345     2.100840  \n",
       "5.0                     18.796992    15.413534  \n",
       "6.0                      7.894737    47.368421  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf.get_categories_per_topic(n_topics, \n",
    "                            lda, \n",
    "                            bow_vect, \n",
    "                            products_text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519165d9",
   "metadata": {},
   "source": [
    "On pourrait associer certain topic à certaines catégories. Par exemple:\n",
    "\n",
    "- topic #0 : Baby Care (52%)     \n",
    "- topic #2 : Beauty and Personal Care (86%) \n",
    "- topic #6 : Computers (47%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce1b2fd",
   "metadata": {},
   "source": [
    "##### 6.1.1.2 Données TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9538e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitter sur les données\n",
    "lda.fit(tfidf_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fb2b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Catégories in LDA model (TF-IDF):\")\n",
    "tf_feature_names = tfidf.get_feature_names()\n",
    "\n",
    "pf.print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92906b2",
   "metadata": {},
   "source": [
    "Analysons les proportions de produits des différentes catégories connues pour chaque topic, afin de voir s'il est possible de faire des couples (catégorie, topic) uniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d809cbf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>% Home Furnishing</th>\n",
       "      <th>% Baby Care</th>\n",
       "      <th>% Watches</th>\n",
       "      <th>% Home Decor &amp; Festive Needs</th>\n",
       "      <th>% Kitchen &amp; Dining</th>\n",
       "      <th>% Beauty and Personal Care</th>\n",
       "      <th>% Computers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>1.680672</td>\n",
       "      <td>7.563025</td>\n",
       "      <td>60.924370</td>\n",
       "      <td>2.941176</td>\n",
       "      <td>8.403361</td>\n",
       "      <td>14.705882</td>\n",
       "      <td>3.781513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.347826</td>\n",
       "      <td>86.956522</td>\n",
       "      <td>4.347826</td>\n",
       "      <td>4.347826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>16.300940</td>\n",
       "      <td>4.702194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.852665</td>\n",
       "      <td>12.852665</td>\n",
       "      <td>22.570533</td>\n",
       "      <td>30.721003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>22.488038</td>\n",
       "      <td>27.990431</td>\n",
       "      <td>1.196172</td>\n",
       "      <td>22.966507</td>\n",
       "      <td>8.373206</td>\n",
       "      <td>7.894737</td>\n",
       "      <td>9.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>86.842105</td>\n",
       "      <td>13.157895</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       % Home Furnishing  % Baby Care  % Watches  \\\n",
       "Topic                                              \n",
       "0.0             1.680672     7.563025  60.924370   \n",
       "1.0             0.000000     0.000000   0.000000   \n",
       "2.0             0.000000     0.000000   0.000000   \n",
       "3.0            16.300940     4.702194   0.000000   \n",
       "4.0            22.488038    27.990431   1.196172   \n",
       "5.0             0.000000     0.000000   0.000000   \n",
       "6.0             0.000000     0.000000   0.000000   \n",
       "\n",
       "       % Home Decor & Festive Needs  % Kitchen & Dining  \\\n",
       "Topic                                                     \n",
       "0.0                        2.941176            8.403361   \n",
       "1.0                       50.000000            0.000000   \n",
       "2.0                        4.347826           86.956522   \n",
       "3.0                       12.852665           12.852665   \n",
       "4.0                       22.966507            8.373206   \n",
       "5.0                       30.000000           10.000000   \n",
       "6.0                        0.000000           86.842105   \n",
       "\n",
       "       % Beauty and Personal Care  % Computers  \n",
       "Topic                                           \n",
       "0.0                     14.705882     3.781513  \n",
       "1.0                     50.000000     0.000000  \n",
       "2.0                      4.347826     4.347826  \n",
       "3.0                     22.570533    30.721003  \n",
       "4.0                      7.894737     9.090909  \n",
       "5.0                     20.000000    40.000000  \n",
       "6.0                     13.157895     0.000000  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf.get_categories_per_topic(n_topics, \n",
    "                            lda, \n",
    "                            tfidf_vect, \n",
    "                            products_text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29406c65",
   "metadata": {},
   "source": [
    "On pourrait associer certain topic à certaines catégories. Par exemple:\n",
    "\n",
    "- topic #0 : Watches (61%)\n",
    "- topic #2 : Kitchen & Dining (87%)  \n",
    "- topic #5 : Computers (40%) \n",
    "- topic #6 : Kitchen & Dining (87%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e7604f",
   "metadata": {},
   "source": [
    "#### 6.1.2 Negative Matrix Factorization (NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7778fa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = 7\n",
    "n_top_words = 10\n",
    "\n",
    "nmf = NMF(n_components=n_topics, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa9be85",
   "metadata": {},
   "source": [
    "##### 6.1.2.1 Données Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2278cfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_feature_names = bow.get_feature_names()\n",
    "\n",
    "nmf.fit(bow_vect)\n",
    "\n",
    "pf.print_top_words(nmf, bow_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf98a01",
   "metadata": {},
   "source": [
    "Analysons les proportions de produits des différentes catégories connues pour chaque topic, afin de voir s'il est possible de faire des couples (catégorie, topic) uniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "37e8de99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>% Home Furnishing</th>\n",
       "      <th>% Baby Care</th>\n",
       "      <th>% Watches</th>\n",
       "      <th>% Home Decor &amp; Festive Needs</th>\n",
       "      <th>% Kitchen &amp; Dining</th>\n",
       "      <th>% Beauty and Personal Care</th>\n",
       "      <th>% Computers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>29.302326</td>\n",
       "      <td>9.302326</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>31.162791</td>\n",
       "      <td>15.813953</td>\n",
       "      <td>8.837209</td>\n",
       "      <td>5.116279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.611111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>17.452830</td>\n",
       "      <td>8.254717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.396226</td>\n",
       "      <td>9.198113</td>\n",
       "      <td>24.528302</td>\n",
       "      <td>22.169811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.030303</td>\n",
       "      <td>6.060606</td>\n",
       "      <td>9.090909</td>\n",
       "      <td>81.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>9.615385</td>\n",
       "      <td>86.538462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.846154</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.026316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>0.657895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       % Home Furnishing  % Baby Care  % Watches  \\\n",
       "Topic                                              \n",
       "0.0            29.302326     9.302326   0.465116   \n",
       "1.0             0.000000     1.388889   0.000000   \n",
       "2.0            17.452830     8.254717   0.000000   \n",
       "3.0             0.000000     0.000000   0.000000   \n",
       "4.0             9.615385    86.538462   0.000000   \n",
       "5.0             6.000000     8.000000   0.000000   \n",
       "6.0             0.000000     0.000000  98.026316   \n",
       "\n",
       "       % Home Decor & Festive Needs  % Kitchen & Dining  \\\n",
       "Topic                                                     \n",
       "0.0                       31.162791           15.813953   \n",
       "1.0                        0.000000           98.611111   \n",
       "2.0                       18.396226            9.198113   \n",
       "3.0                        3.030303            6.060606   \n",
       "4.0                        0.000000            0.000000   \n",
       "5.0                        8.000000            8.000000   \n",
       "6.0                        0.000000            0.000000   \n",
       "\n",
       "       % Beauty and Personal Care  % Computers  \n",
       "Topic                                           \n",
       "0.0                      8.837209     5.116279  \n",
       "1.0                      0.000000     0.000000  \n",
       "2.0                     24.528302    22.169811  \n",
       "3.0                      9.090909    81.818182  \n",
       "4.0                      3.846154     0.000000  \n",
       "5.0                     36.000000    34.000000  \n",
       "6.0                      1.315789     0.657895  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf.get_categories_per_topic(n_topics, \n",
    "                            nmf, \n",
    "                            bow_vect,\n",
    "                            products_text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c973ef6",
   "metadata": {},
   "source": [
    "On pourrait associer certain topic à certaines catégories. Par exemple:\n",
    "\n",
    "- topic #1 : Kitchen & Dining (99%)     \n",
    "- topic #3 : Computers (82%)      \n",
    "- topic #4 : Baby Care (87%)\n",
    "- topic #6 : Watches (98%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b1bfbd",
   "metadata": {},
   "source": [
    "##### 6.1.2.2 Données TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4aea656",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_feature_names = tfidf.get_feature_names()\n",
    "\n",
    "nmf.fit(tfidf_vect)\n",
    "\n",
    "pf.print_top_words(nmf, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec32bb16",
   "metadata": {},
   "source": [
    "Analysons les proportions de produits des différentes catégories connues pour chaque topic, afin de voir s'il est possible de faire des couples (catégorie, topic) uniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2858809e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>% Home Furnishing</th>\n",
       "      <th>% Baby Care</th>\n",
       "      <th>% Watches</th>\n",
       "      <th>% Home Decor &amp; Festive Needs</th>\n",
       "      <th>% Kitchen &amp; Dining</th>\n",
       "      <th>% Beauty and Personal Care</th>\n",
       "      <th>% Computers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.104972</td>\n",
       "      <td>82.320442</td>\n",
       "      <td>3.867403</td>\n",
       "      <td>4.972376</td>\n",
       "      <td>4.972376</td>\n",
       "      <td>2.762431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.769231</td>\n",
       "      <td>86.153846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>23.762376</td>\n",
       "      <td>51.980198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.881188</td>\n",
       "      <td>5.940594</td>\n",
       "      <td>5.940594</td>\n",
       "      <td>0.495050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>5.586592</td>\n",
       "      <td>7.821229</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.905028</td>\n",
       "      <td>11.452514</td>\n",
       "      <td>31.843575</td>\n",
       "      <td>20.391061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.581395</td>\n",
       "      <td>69.767442</td>\n",
       "      <td>4.651163</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>81.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>0.990099</td>\n",
       "      <td>3.960396</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>9.900990</td>\n",
       "      <td>1.980198</td>\n",
       "      <td>11.881188</td>\n",
       "      <td>70.297030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       % Home Furnishing  % Baby Care  % Watches  \\\n",
       "Topic                                              \n",
       "0.0             0.000000     1.104972  82.320442   \n",
       "1.0             0.000000     3.076923   0.000000   \n",
       "2.0            23.762376    51.980198   0.000000   \n",
       "3.0             5.586592     7.821229   0.000000   \n",
       "4.0             0.000000     0.000000   0.000000   \n",
       "5.0            81.000000     9.000000   0.000000   \n",
       "6.0             0.990099     3.960396   0.990099   \n",
       "\n",
       "       % Home Decor & Festive Needs  % Kitchen & Dining  \\\n",
       "Topic                                                     \n",
       "0.0                        3.867403            4.972376   \n",
       "1.0                       10.769231           86.153846   \n",
       "2.0                       11.881188            5.940594   \n",
       "3.0                       22.905028           11.452514   \n",
       "4.0                       25.581395           69.767442   \n",
       "5.0                        9.000000            0.000000   \n",
       "6.0                        9.900990            1.980198   \n",
       "\n",
       "       % Beauty and Personal Care  % Computers  \n",
       "Topic                                           \n",
       "0.0                      4.972376     2.762431  \n",
       "1.0                      0.000000     0.000000  \n",
       "2.0                      5.940594     0.495050  \n",
       "3.0                     31.843575    20.391061  \n",
       "4.0                      4.651163     0.000000  \n",
       "5.0                      1.000000     0.000000  \n",
       "6.0                     11.881188    70.297030  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf.get_categories_per_topic(n_topics, \n",
    "                            nmf, \n",
    "                            tfidf_vect,\n",
    "                            products_text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b480cd",
   "metadata": {},
   "source": [
    "On pourrait associer certain topic à certaines catégories. Par exemple:\n",
    "\n",
    "- topic 0 : Watches (82%)            \n",
    "- topic 1 : Kitchen & Dining (86%)           \n",
    "- topic 2 : Baby Care (52%)\n",
    "- topic 4 : Kitchen & Dining (70%)\n",
    "- topic 5 : Home Furnishing (81%)               \n",
    "- topic 6 : Computers (70%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b875f00",
   "metadata": {},
   "source": [
    "### 6.2  TRANSFER LEARNING\n",
    "\n",
    "Nous allons implémenter un algorithme de type CNN Transfer Learning en utilisant le modèle VGG-16\n",
    "\n",
    "- VGG-16 est une version du réseau de neurones convolutif VGG-Net.\n",
    "- VGG-16 est constitué de plusieurs couches, dont 13 couches de convolution et 3 fully-connected. Il doit donc apprendre les poids de 16 couches.\n",
    "- Il prend en entrée une image en couleurs de taille 224  × 224 px et la classifie dans une des 1000 classes. Il renvoie donc un vecteur de taille 1000, qui contient les probabilités d'appartenance à chacune des classes. \n",
    "\n",
    "- le Transfer Learning consiste à utiliser le modèle VGG16 pré-entraîné sur ImageNet (ImageNet est un projet de recherche visant à développer une grande base de données d'images avec des annotations, c'est-à-dire des images et leurs descriptions).\n",
    "\n",
    "**3 étapes**\n",
    "\n",
    ">1. ÉTAPE 1 - Chargement des images, extraction des features (Preprocess each image according to the input accepted by the transfer learning model and convert each image to the respective vector by using the weights from the transfer learning model. Then flatten and store all the image weights in a list)\n",
    "\n",
    ">2. ÉTAPE 2 - Réduction de dimension (Apply TSNE dimension reduction (initialized  with a PCA))\n",
    "\n",
    ">3. ÉTAPE 3 - Clustering (Apply clustering with k-means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba593ac",
   "metadata": {},
   "source": [
    "#### 6.2.1 ÉTAPE 1 - Chargement des images, extraction des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e11677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisation de VGG16 pré-entraîné sur ImageNet avec les images d'origine\n",
    "# VGG16 imports\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# Liste\n",
    "vgg16_all_features = []\n",
    "\n",
    "# Instanciation du modèle\n",
    "model_vgg16 = VGG16(weights='imagenet', include_top=False)\n",
    "# Résumé de l'architecture du modèle\n",
    "model_vgg16.summary()\n",
    "\n",
    "for rep_image in products_image_data['image_loc']:\n",
    "\n",
    "    # Charger l'image et la redimensionner à la taille\n",
    "    # requise de 224×224 pixels.\n",
    "    img = image.load_img(rep_image, target_size=(224, 224))\n",
    "    # Convertir les pixels en un tableau NumPy afin de pouvoir travailler\n",
    "    # avec dans Keras\n",
    "    img = image.img_to_array(img)\n",
    "    # Redimensionnement\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    # Préparer de nouvelles entrées pour le réseau.\n",
    "    img = preprocess_input(img)\n",
    "\n",
    "    # obtenir une prédiction de la probabilité d'appartenance\n",
    "    # de l'image à chacun des 1000 types d'objets connus.\n",
    "    vgg16_feature = model_vgg16.predict(img)\n",
    "    # Ajouter la feature prédite en nparray à la liste\n",
    "    vgg16_all_features.append(np.array(vgg16_feature).flatten())\n",
    "\n",
    "vgg16_all_features = np.array(vgg16_all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f90c5dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe de sauvegarde des BOVW VGG16\n",
    "# Association des features à chaque image\n",
    "products_image_data['vgg16_bovw'] = [vgg16_all_features[i] for i in range(products_image_data.shape[0])]\n",
    "# Dataframe de travail\n",
    "df_vgg16_bovw = products_image_data[['image', 'image_loc', 'category', 'vgg16_bovw']]\n",
    "# Constituer le dataframe de vecteurs de BOVW VGG16\n",
    "df_vgg16_vectors = pd.DataFrame.from_records(vgg16_all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd663061",
   "metadata": {},
   "source": [
    "#### 6.2.2 ÉTAPE 2 - Réduction de dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3b632d",
   "metadata": {},
   "source": [
    "**PCA**\n",
    "\n",
    "La réduction PCA tout en gardant 99% de variance expliquée "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac9ea44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dimensions dataset avant réduction PCA : \", df_vgg16_vectors.shape)\n",
    "pca = decomposition.PCA(n_components=0.99)\n",
    "pca_results_vgg16 = pca.fit_transform(df_vgg16_vectors)\n",
    "print(\"Dimensions dataset après réduction PCA : \", pca_results_vgg16.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab03485",
   "metadata": {},
   "source": [
    "**TSNE**\n",
    "\n",
    "Réduction de dimension en 2 composantes T-SNE pour affichage en 2D des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9742f7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = manifold.TSNE(n_components=2, perplexity=30, \n",
    "                     n_iter=2000, init='random', random_state=6)\n",
    "tsne_results_vgg16 = tsne.fit_transform(pca_results_vgg16)\n",
    "\n",
    "df_tsne_vgg16 = pd.DataFrame(tsne_results_vgg16[:,0:2], columns=['tsne1', 'tsne2'])\n",
    "df_tsne_vgg16[\"class\"] = products_image_data[\"category\"]\n",
    "print(df_tsne_vgg16.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e17d73",
   "metadata": {},
   "source": [
    "**Visualisation**\n",
    "\n",
    "Affichage T-SNE selon les catégories d'images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d203ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.scatterplot(\n",
    "    x=\"tsne1\", y=\"tsne2\", hue=\"class\", data=df_tsne_vgg16, legend=\"brief\",\n",
    "    palette=sns.color_palette('tab10', n_colors=7), s=50, alpha=0.8)\n",
    "\n",
    "plt.title('TSNE (VGG-16) selon les catégories produit', fontsize = 30, pad = 35, fontweight = 'bold')\n",
    "plt.xlabel('tsne1', fontsize = 26, fontweight = 'bold')\n",
    "plt.ylabel('tsne2', fontsize = 26, fontweight = 'bold')\n",
    "plt.legend(prop={'size': 14}) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6b5480",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "Le regroupement par catégories produits semble meilleur que ce qu'on a pu observer sur les données SIFT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a816d25",
   "metadata": {},
   "source": [
    "#### 6.2.3 ÉTAPE 3 - Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd07bbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création de clusters à partir du T-SNE \n",
    "X = df_tsne_vgg16[[\"tsne1\",\"tsne2\"]]\n",
    "\n",
    "cls = KMeans(n_clusters=N_CLUSTERS, init='k-means++', random_state=0)\n",
    "cls.fit(X)\n",
    "\n",
    "df_tsne_vgg16[\"cluster\"] = cls.labels_\n",
    "\n",
    "sil = silhouette_score(X,cls.labels_,metric=\"euclidean\")\n",
    "print(\"Le score de silhouette est\", sil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1345ba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affichage des images selon clusters et calcul ARI de similarité catégories images / clusters\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.scatterplot(\n",
    "    x=\"tsne1\", y=\"tsne2\",\n",
    "    hue=\"cluster\",\n",
    "    palette=sns.color_palette('tab10', n_colors=7), s=50, alpha=0.8,\n",
    "    data=df_tsne_vgg16,\n",
    "    legend=\"brief\")\n",
    "\n",
    "plt.title('TSNE (VGG-16) selon les clusters', fontsize = 30, pad = 35, fontweight = 'bold')\n",
    "plt.xlabel('tsne1', fontsize = 26, fontweight = 'bold')\n",
    "plt.ylabel('tsne2', fontsize = 26, fontweight = 'bold')\n",
    "plt.legend(prop={'size': 14}) \n",
    "\n",
    "plt.show()\n",
    "\n",
    "labels = products_image_data[\"label\"]\n",
    "print(\"ARI : \", metrics.adjusted_rand_score(labels, cls.labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bee75bc",
   "metadata": {},
   "source": [
    "**Observations** \n",
    "- le score ARI amélioré (par rapport à celui obtenu sur avec les features SIFT)\n",
    "- le score de silhouette est egalement amélioré mais reste moins bon que celui obtenu sur les données textes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ed94d6",
   "metadata": {},
   "source": [
    "**Qualité de la catégorisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f37a525",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tsne_vgg16.groupby(\"cluster\").count()[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafb412f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.plot_stacked_bar_clust_vs_cat(df_tsne_vgg16[\"cluster\"],\n",
    "                              df_tsne_vgg16[\"class\"],\n",
    "                              df_tsne_vgg16,   \n",
    "                              palette='tab10',\n",
    "                              figsize=(7,4),\n",
    "                              bboxtoanchor=(1,1), ylim=(0,290))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9827c625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>cluster</th>\n",
       "      <th>5</th>\n",
       "      <th>4</th>\n",
       "      <th>6</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "      <th>cat_sum</th>\n",
       "      <th>cat_matching_score_pct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baby Care</th>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beauty and Personal Care</th>\n",
       "      <td>13</td>\n",
       "      <td>84</td>\n",
       "      <td>9</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Computers</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>80</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Home Decor &amp; Festive Needs</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>59</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Home Furnishing</th>\n",
       "      <td>55</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>47</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kitchen &amp; Dining</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Watches</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>150</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clust_sum</th>\n",
       "      <td>167</td>\n",
       "      <td>106</td>\n",
       "      <td>124</td>\n",
       "      <td>268</td>\n",
       "      <td>156</td>\n",
       "      <td>98</td>\n",
       "      <td>131</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clust_matching_score_pct</th>\n",
       "      <td>52</td>\n",
       "      <td>79</td>\n",
       "      <td>40</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>82</td>\n",
       "      <td>98</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "cluster                      5   4   6   2   0  1   3 cat_sum  \\\n",
       "class                                                           \n",
       "Baby Care                   87   0   5  26  30  2   0     150   \n",
       "Beauty and Personal Care    13  84   9  34   4  6   0     150   \n",
       "Computers                    7   3  50  80   7  3   0     150   \n",
       "Home Decor & Festive Needs   4   9  14  59  62  0   2     150   \n",
       "Home Furnishing             55   6   3  32  47  7   0     150   \n",
       "Kitchen & Dining             0   4  34  30   2 80   0     150   \n",
       "Watches                      1   0   9   7   4  0 129     150   \n",
       "clust_sum                  167 106 124 268 156 98 131       -   \n",
       "clust_matching_score_pct    52  79  40  22  30 82  98       -   \n",
       "\n",
       "cluster                    cat_matching_score_pct  \n",
       "class                                              \n",
       "Baby Care                                      58  \n",
       "Beauty and Personal Care                       56  \n",
       "Computers                                      33  \n",
       "Home Decor & Festive Needs                     39  \n",
       "Home Furnishing                                31  \n",
       "Kitchen & Dining                               53  \n",
       "Watches                                        86  \n",
       "clust_sum                                       -  \n",
       "clust_matching_score_pct                        -  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cat_clust_confmat = pf.plot_conf_matrix_cat_vs_clust(df_tsne_vgg16['class'],\n",
    "                                                  df_tsne_vgg16['cluster'],\n",
    "                                                  normalize=False,\n",
    "                                                  margins_sums=True,\n",
    "                                                  margins_score=True)\n",
    "with pd.option_context('display.float_format', '{:.0f}'.format):\n",
    "    display(cat_clust_confmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f76b98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Affiche la matrice de confusion (Vraies catégories vs. Clusters)\n",
    "\n",
    "cm = pf.plot_conf_matrix_cat_vs_clust(df_tsne_vgg16['class'],\n",
    "                            df_tsne_vgg16['cluster'],\n",
    "                            normalize=False,\n",
    "                            margins_sums=False,\n",
    "                            margins_score=False)\n",
    "pf.plot_heatmap(cm, \"Confusion matrix | true categories vs. clusters\",\n",
    "             figsize=(8, 4), vmin=0, vmax=150, center=75,\n",
    "                 palette=sns.color_palette(\"viridis\", 20), shape='rect',\n",
    "                 fmt='.0f', robust=False, fig=None, ax=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a585b461",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "- ARI = 0.28\n",
    "- Silhouette = 0.38\n",
    "- 514 erreurs de catégorisation\n",
    "- On a une meilleure classification des images en utilisation les features obtenus par Tranfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb5810a-ae33-4bad-9c88-a071d9595600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6f3168-cebe-49a1-9464-119625e91382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad854a7-1b42-461b-be73-3c6858f2fd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/features/build_features.py\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "def extract_image_features(img_paths):\n",
    "    model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "    features = []\n",
    "    \n",
    "    for path in img_paths:\n",
    "        if path is None:\n",
    "            features.append(np.zeros(2048))  # Dimension des features ResNet50\n",
    "            continue\n",
    "            \n",
    "        img = image.load_img(path, target_size=(224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        features.append(model.predict(x).flatten())\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "def build_complete_features(df, text_vectorizer, image_features):\n",
    "    # Features textuelles\n",
    "    text_features = text_vectorizer.transform(df['description'])\n",
    "    \n",
    "    # Combinaison\n",
    "    combined_features = np.hstack([text_features.toarray(), image_features])\n",
    "    \n",
    "    return combined_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409b5294-97ae-40cd-9158-f0752121e9d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
