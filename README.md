
# ğŸ“¦ Classification Automatique de Biens de Consommation

## ğŸ“š Contexte du Projet

La "Place de MarchÃ©" est une plateforme dâ€™e-commerce sur laquelle les vendeurs publient des articles Ã  vendre en fournissant une **description textuelle** et une **photo**. Actuellement, la catÃ©gorisation des articles est **manuelle**, sujette Ã  erreurs, incohÃ©rente, et fastidieuse.

ğŸ¯ **Objectif** : Automatiser la classification des articles (produits) dans les bonnes catÃ©gories, en exploitant **le texte et/ou lâ€™image**, afin de :

- Garantir une **meilleure fiabilitÃ©** et **cohÃ©rence** de la catÃ©gorisation.
- **Optimiser lâ€™expÃ©rience utilisateur** lors de la mise en ligne ou de la recherche de produits.

---

## ğŸ“ Structure du RÃ©pertoire

```
classification-produits/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/               # DonnÃ©es brutes (descriptions, images)
â”‚   â”œâ”€â”€ processed/         # DonnÃ©es aprÃ¨s nettoyage et transformations
â”‚   â””â”€â”€ features/          # Vecteurs de features extraits (TF-IDF, SIFT, etc.)
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_preprocessing_text.ipynb     # Nettoyage des textes
â”‚   â”œâ”€â”€ 02_preprocessing_images.ipynb   # Traitement des images
â”‚   â”œâ”€â”€ 03_feature_extraction.ipynb     # Extraction des features textuelles et visuelles
â”‚   â”œâ”€â”€ 04_dim_reduction.ipynb          # RÃ©duction de dimension (PCA, t-SNE)
â”‚   â”œâ”€â”€ 05_clustering.ipynb             # Algorithmes de clustering (TF-IDF, SIFT)
â”‚   â””â”€â”€ 06_topic_modeling.ipynb         # LDA / NMF pour exploration de topics
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ cnn_transfer_learning.py        # Script pour test CNN (Transfer Learning)
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ figures/                        # Graphiques t-SNE, wordclouds, etc.
â”‚   â””â”€â”€ metrics/                        # Silhouette score, ARI, etc.
â”‚
â”œâ”€â”€ app/
â”‚   â””â”€â”€ demo_app.py                     # DÃ©mo de lâ€™application de classification
â”‚
â”œâ”€â”€ requirements.txt                    # Librairies nÃ©cessaires
â”œâ”€â”€ README.md                           # Ce fichier
â””â”€â”€ .gitignore                          # Fichiers Ã  ignorer par Git
```

---

## ğŸ” DÃ©tails Techniques

### ğŸ“Š Jeu de DonnÃ©es

- 1050 produits, rÃ©partis dans **7 catÃ©gories de niveau 0**.
- Types de donnÃ©es :
  - **Textuelles** : nom, description, marque, catÃ©gorie.
  - **Visuelles** : images isolÃ©es sur fond blanc.

---

### ğŸ”§ PrÃ©traitement

#### Texte
- Suppression de la ponctuation
- Tokenisation
- Filtrage (stopwords, tokens < 2 lettres)
- Stemming & lemmatisation
- Vectorisation : **Bag of Words** (BoW), **TF-IDF**

#### Images
- Correction d'exposition & contraste
- RÃ©duction du bruit
- Passage en niveaux de gris
- Redimensionnement : `224x224`

---

### ğŸ“ˆ Extraction des CaractÃ©ristiques (Features)

- **Textuelles** : TF-IDF, BoW
- **Visuelles** : 
  - **SIFT** (bag of visual words)
  - **CNN** prÃ©entraÃ®nÃ© sur ImageNet (via Transfer Learning)

---

### ğŸ§¬ RÃ©duction de Dimension

- **PCA** : Conserve jusquâ€™Ã  99% de la variance
- **t-SNE** : Projection 2D pour visualisation

---

### ğŸ“Œ Clustering

- Algorithmes : K-Means
- Ã‰valuation : 
  - **Silhouette Score**
  - **ARI (Adjusted Rand Index)**

| MÃ©thode | DonnÃ©e       | Silhouette | ARI   |
|---------|--------------|------------|-------|
| KMeans  | TF-IDF       | 0.47       | 0.43  |
| KMeans  | SIFT         | 0.35       | -0.0008 |

---

### ğŸ§  Analyse ThÃ©matique (Topic Modeling)

- MÃ©thodes : **LDA**, **NMF**
- RÃ©sultat : Certains topics correspondent bien Ã  des catÃ©gories de produits (ex. Watches, Baby Careâ€¦)

---

### ğŸš€ Application

Une dÃ©monstration simple est disponible via le script `app/demo_app.py`.

---

## ğŸ”§ Requirements

```
numpy
pandas
scikit-learn
matplotlib
seaborn
nltk
opencv-python
tensorflow / keras
scikit-image
gensim
umap-learn
```

---

## ğŸ‘¥ Ã‰quipe

- **Chaka KONE**
- **Mahamadi Bassirou COMPAORE**
- **Moussa DIAKITE**

**Superviseure** : Mme DIAW Mously â€“ Lead ML Engineer, Experte IA & MLOps

---

## ğŸ“¬ Contact

Pour toute question, contactez-nous via [GitHub].
